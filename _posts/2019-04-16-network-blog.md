---
title: 网络协议详解
subtitle: 网络协议的学习
layout: post
---

通过这篇文章，回顾学习一下基础的网络协议。



**网络协议相关分层**

| 协议层 | 包含协议                                    |
| ------ | ------------------------------------------- |
| 应用层 | DHCP、HTTP、HTTPS、P2P、DNS、GTP、RPC、RTMP |
| 传输层 | UDP、TCP                                    |
| 网络层 | CIMP、IP、BGP、GRE、ICMP、OSPF、IPSec       |
| 链路层 | ARP、VLAN、STP                              |
| 物理层 | 网络跳线                                    |



下面我们会从底向上的方向详细讲解，分析相关的网络协议。



### 一、 网络分层的真实含义

网络为什么要分层? 

```
这里我们先探讨第一个问题，网络为什么要分层?因为，是个复杂的程序都要分层。
```

理解计算机网络中的概念，一个很好的角度是，想象网络包就是一段 Buffer，或者一块内存，是有格式的。同时，想象自己是一个处理网络包的程序，而且这个程序可以跑在电脑上，可以跑在服务器上，可以跑在交换机上，也可以跑在路由器上。**你想象自己有很多的网口，从某个口拿进一个网络包来，用自己的程序处理一下，再从另一个网口发送出去**。

当然网络包的格式很复杂，这个程序也很复杂。**复杂的程序都要分层，这是程序设计的要求**。比如，复杂的电商还会分数据库层、缓存层、Compose 层、Controller 层和接入层，每一层专注做本层的事情。

![](/Users/nali/songyintao/SongYintao.github.io/img/network1.jpg)

```
当一个网络包从一个网口经过的时候，你看到了，首先先看看要不要请进来，处理一把。有的网口配置
了混杂模式，凡是经过的，全部拿进来。
```

拿进来以后，就要交给一段程序来处理。于是，你调用`process_layer2(buffer)`。当然，这是一个假的函 数。但是你明白其中的意思，知道肯定是有这么个函数的。那这个函数是干什么的呢?从 Buffer 中，摘掉二层的头，看看，应该根据头里面的内容做什么操作。 

假设你发现这个包的 MAC 地址和你的相符，那说明就是发给你的，于是需要调用`process_layer3(buffer)`。这个时候，Buffer 里面往往就没有二层的头了，因为已经在上一个函数的处理过程中拿掉了，或者将开始的偏移量移动了一下。在这个函数里面，摘掉三层的头，**看看到底是发送给自己的，还是希望自己转发出去的**。

如何判断呢?如果 IP 地址不是自己的，那就应该转发出去;如果 IP 地址是自己的，那就是发给自己的。根据 IP 头里面的标示，拿掉三层的头，进行下一层的处理，到底是调用 `process_tcp(buffer)` 呢，还是调用 `process_udp(buffer)` 呢?

假设这个地址是 TCP 的，则会调用`process_tcp(buffer)`。这时候，Buffer 里面没有三层的头，就需要**查看四层的头**，**看这是一个发起，还是一个应答，又或者是一个正常的数据包**，**然后分别由不同的逻辑进行处理**。如果是发起或者应答，接下来可能要发送一个回复包;如果是一个正常的数据包，就需要交给上层了。交给谁呢?是不是有 `process_http(buffer) `函数呢?

没有的，如果你是一个网络包处理程序，你不需要有 `process_http(buffer)`，而是应该交给应用去处理。交给哪个应用呢?在四层的头里面有端口号，不同的应用监听不同的端口号。如果发现浏览器应用在监听这个端口，那你发给浏览器就行了。至于浏览器怎么处理，和你没有关系。

浏览器自然是解析 HTML，显示出页面来。电脑的主人看到页面很开心，就点了鼠标。点击鼠标的动作被浏览器捕获。浏览器知道，又要发起另一个 HTTP 请求了，于是使用端口号，将请求发给了你。

你应该调用`send_tcp(buffer)`。不用说，Buffer 里面就是 HTTP 请求的内容。这个函数里面加一个 TCP的头，记录下源端口号。浏览器会给你目的端口号，一般为 80 端口。

然后调用`send_layer3(buffer)`。Buffer 里面已经有了 HTTP 的头和内容，以及 TCP 的头。在这个函数里面加一个 IP 的头，记录下源 IP 的地址和目标 IP 的地址。

然后调用`send_layer2(buffer)`。Buffer 里面已经有了 HTTP 的头和内容、TCP 的头，以及 IP 的头。这个函数里面要加一下 MAC 的头，记录下源 MAC 地址，得到的就是本机器的 MAC 地址和目标的 MAC地址。不过，这个要看当前知道不知道，知道就直接加上;不知道的话，就要通过一定的协议处理过程，找到 MAC 地址。反正要填一个，不能空着。

万事俱备，只要 Buffer 里面的内容完整，就可以从网口发出去了，你作为一个程序的任务就算告一段落了。



**揭秘层与层之间的关系** 

**这里要记住一点**:**只要是在网络上跑的包，都是完整的。可以有下层没上层，绝对不可能有上层没下层。**

所以，对 TCP 协议来说，三次握手也好，重试也好，只要想发出去包，就要有 IP 层和 MAC 层，不然 是发不出去的。 

所谓的二层设备、三层设备，都是这些设备上跑的程序不同而已。一个 HTTP 协议的包经过一个二层设备，二层设备收进去的是整个网络包。这里面 HTTP、TCP、 IP、 MAC 都有。什么叫二层设备呀，就是只把 MAC 头摘下来，看看到底是丢弃、转发，还是自己留着。那什么叫三层设备呢?就是把 MAC头摘下来之后，再把 IP 头摘下来，看看到底是丢弃、转发，还是自己留着。

### 二、DHCP与PXE：IP怎么来的？怎么没的？

如何配置ip地址？

我们可以使用命令行自己配置一个地址。可以使用`ifconfig`，也可以使用`ip addr`。设置好之后使用这些命令，将网卡up一下就好了，就可以开始工作了。

使用`net-tools`:

```shell
sudo ifconfig eth1 10.0.0.1/24
sudo ifconfig eth1 up
```

使用`iproute2`:

```shell
sudo ip addr add 10.0.0.1/24 dev eht1
sudo ip link set up eht1
```



Linux 首先会判断，要去的这个地址和我是一个网段的吗，或者和我的一个网卡是同一网段的吗?只有是一个网段的，它才会发送 ARP 请求，获取 MAC 地址。如果发现不是呢?

Linux 默认的逻辑是，如果这是一个跨网段的调用，它便不会直接将包发送到网络上，而是企图将包发送到网关。

如果你配置了网关的话，Linux 会获取网关的 MAC 地址，然后将包发出去。对于 192.168.1.6 这台机器来讲，虽然路过它家门的这个包，目标 IP 是它，但是无奈 MAC 地址不是它的，所以它的网卡是不会把包收进去的。

如果没有配置网关呢?那包压根就发不出去。

如果将网关配置为 192.168.1.6 呢?不可能，Linux 不会让你配置成功的，因为**网关要和当前的网络至少一个网卡是同一个网段**的，怎么可能 16.158.23.6 的网关是 192.168.1.6 呢?

所以，**当你需要手动配置一台机器的网络 IP 时**，一定要好好问问你的网络管理员。如果在机房里面，要去网络管理员那里申请，让他给你分配一段正确的 IP 地址。当然，**真正配置的时候，一定不是直接用命令配置的，而是放在一个配置文件里面**。不同系统的配置文件格式不同，但是无非就是 **CIDR、子网掩码、广播地址和网关地址**。

#### 1. 动态主机配置协议(DHCP)

原来配置 IP 有这么多门道儿啊。你可能会问了，配置了 IP 之后一般不能变的，配置一个服务端的机器还可以，但是如果是客户端的机器呢?我抱着一台笔记本电脑在公司里走来走去，或者白天来晚上走，每次使用都要配置 IP 地址，那可怎么办?还有人事、行政等非技术人员，如果公司所有的电脑都需要 IT人员配置，肯定忙不过来啊。

因此，我们需要有一个**自动配置的协议**，也就是称**动态主机配置协议**(Dynamic Host Configuration Protocol)，简称**DHCP**。

有了这个协议，网络管理员就轻松多了。他只需要配置一段共享的 IP 地址。每一台新接入的机器都通过DHCP 协议，来这个共享的 IP 地址里申请，然后自动配置好就可以了。等人走了，或者用完了，还回去，这样其他的机器也能用。

所以说，如果是**数据中心里面的服务器，IP 一旦配置好，基本不会变**，这就相当于买房自己装修。DHCP 的方式就相当于租房。你不用装修，都是帮你配置好的。你暂时用一下，用完退租就可以了。

##### **解析 DHCP 的工作方式** 

当一台机器新加入一个网络的时候，肯定一脸懵，啥情况都不知道，**只知道自己的 MAC 地址**。怎么 办?先吼一句，我来啦，有人吗?这时候的沟通基本靠“吼”。这一步，我们称为**DHCP Discover**。 

新来的机器使用 IP 地址 0.0.0.0 发送了一个广播包，目的 IP 地址为 255.255.255.255。**广播包封装在 UDP 里**面，`UDP` 封装在` BOOTP` 里面。其实` DHCP `是 `BOOTP `的增强版，但是如果你去抓包的话，很 可能看到的名称还是 BOOTP 协议。 

在这个广播包里面，新人大声喊:我是新来的(Boot request)，我的 MAC 地址是这个，我还没有 IP，谁能给租给我个 IP 地址! 

格式就像这样: 

![](/Users/nali/songyintao/SongYintao.github.io/img/dhcp格式.png)如果一个网络管理员在网络里面配置了**DHCP Server**的话，他就相当于这些 IP 的管理员。他立刻能知道 来了个“新人”。这个时候，我们可以体会 MAC 地址唯一的重要性了。当一台机器带着自己的 MAC 地址加入一个网络的时候，MAC 是它唯一的身份，如果连这个都重复了，就没办法配置了。 

**只有 MAC 唯一，IP 管理员才能知道这是一个新人，需要租给它一个 IP 地址，这个过程我们称为DHCP Offer**。同时，**DHCP Server** 为此客户保留为它提供的 IP 地址，从而不会为其他 DHCP 客户分配此 IP 地址。 

**DHCP Offer 的格式**就像这样，里面有给新人分配的地址。 

​	![](/Users/nali/songyintao/SongYintao.github.io/img/dhcp-offer.png)

**DHCP Server** 仍然**使用广播地址作为目的地址**，因为，**此时请求分配 IP 的新人还没有自己的 IP**。DHCP Server 回复说，我分配了一个可用的 IP 给你，你看如何?**除此之外，服务器还发送了子网掩码、网关和 IP 地址租用期**等信息。

新来的机器很开心，它的“吼”得到了回复，并且有人愿意租给它一个 IP 地址了，这意味着它可以在网络上立足了。当然更令人开心的是，**如果有多个 DHCP Server，这台新机器会收到多个IP 地址**，简直受宠若惊。 

**它会选择其中一个** **DHCP Offer**，**一般是最先到达的那个，并且会向网络发送一个 DHCP Request 广播 数据包，包中包含客户端的 MAC 地址、接受的租约中的 IP 地址、提供此租约的 DHCP 服务器地址等，并告诉所有 DHCP Server 它将接受哪一台服务器提供的 IP 地址，告诉其他 DHCP 服务器，谢谢你们的接纳，并请求撤销它们提供的 IP 地址，以便提供给下一个 IP 租用请求者**。 



此时，**由于还没有得到 DHCP Server 的最后确认**，客户端仍然使用 0.0.0.0 为源 IP 地址、255.255.255.255 为目标地址进行广播。在 BOOTP 里面，接受某个 DHCP Server 的分配的 IP。

**当 DHCP Server 接收到客户机的 DHCP request 之后**，会广播返回给客户机一个 **DHCP ACK 消息包**，**表明已经接受客户机的选择，并将这一 IP 地址的合法租用信息和其他的配置信息都放入该广播包**，发给客户机，欢迎它加入网络大家庭。

最终租约达成的时候，还是需要广播一下，让大家都知道。



##### IP 地址的收回和续租 

既然是租房子，就是有租期的。租期到了，管理员就要将 IP 收回。 

如果不用的话，收回就收回了。就像你租房子一样，如果还要续租的话，不能到了时间再续租，而是要 提前一段时间给房东说。DHCP 也是这样。 

**客户机会在租期过去 50% 的时候，直接向为其提供 IP 地址的DHCP Server 发送 DHCP request 消息包。客户机接收到该服务器回应的 DHCP ACK 消息包，会根据包中所提供的新的租期以及其他已经更新 的 TCP/IP 参数，更新自己的配置。这样，IP 租用更新就完成了**。 

好了，一切看起来完美。DHCP 协议大部分人都知道，但是其实里面隐藏着一个细节，很多人可能不会 去注意。接下来，我就讲一个有意思的事情:**网络管理员不仅能自动分配 IP 地址，还能帮你自动安装操作系统**! 



#### 预启动执行环境(PXE)

普通的笔记本电脑，一般不会有这种需求。因为你拿到电脑时，就已经有操作系统了，即便你自己重装操作系统，也不是很麻烦的事情。但是，在数据中心里就不一样了。**数据中心里面的管理员可能一下子就拿到几百台空的机器，一个个安装操作系统，会累死的**。

所以管理员希望的不仅仅是自动分配 IP 地址，还要自动安装系统。装好系统之后自动分配 IP 地址，直接启动就能用了，这样当然最好了! 

这事儿其实仔细一想，还是挺有难度的。安装操作系统，应该有个光盘吧。数据中心里不能用光盘吧，想了一个办法就是，**可以将光盘里面要安装的操作系统放在一个服务器上，让客户端去下载**。但是客户端放在哪里呢?它怎么知道去哪个服务器上下载呢?客户端总得安装在一个操作系统上呀，可是这个客户端本来就是用来安装操作系统的呀?

其实，**这个过程和操作系统启动的过程有点儿像**。**首先，启动 BIOS。这是一个特别小的小系统，只能干 特别小的一件事情。其实就是读取硬盘的 MBR 启动扇区，将 GRUB 启动起来;然后将权力交给 GRUB，GRUB 加载内核、加载作为根文件系统的 initramfs 文件;然后将权力交给内核;最后内核启动，初始化整个操作系统**。 

那我们安装操作系统的过程，**只能插在 BIOS 启动之后**了。**因为没安装系统之前，连启动扇区都没有**。 因而这个过程叫做**预启动执行环境**(Pre-boot Execution Environment)，简称**PXE**。 

**PXE 协议**分为客户端和服务器端，**由于还没有操作系统，只能先把客户端放在 BIOS 里面**。当计算机启动时，BIOS 把 PXE 客户端调入内存里面，就可以连接到服务端做一些操作了。 

首先，**PXE** 客户端自己也需要有个 IP 地址。**因为 PXE 的客户端启动起来，就可以发送一个 DHCP 的请求，让 DHCP Server 给它分配一个地址。**PXE 客户端有了自己的地址，那它怎么知道 PXE 服务器在哪 里呢?对于其他的协议，都好办，要么人告诉他。例如，告诉浏览器要访问的 IP 地址，或者在配置中告 诉它;例如，微服务之间的相互调用。 

但是 PXE 客户端启动的时候，啥都没有。**好在 DHCP Server 除了分配 IP 地址以外，还可以做一些其他的事情。**这里有一个 DHCP Server 的一个样例配置: 

```shell
ddns-update-style interim;
ignore client-updates;
allow booting;
allow bootp;
subnet 192.168.1.0 netmask 255.255.255.0
{
option routers 192.168.1.1;
option subnet-mask 255.255.255.0;
option time-offset -18000;
default-lease-time 21600;
max-lease-time 43200;
range dynamic-bootp 192.168.1.240 192.168.1.250;
filename "pxelinux.0";
next-server 192.168.1.180;
}
```

按照上面的原理，默认的 DHCP Server 是需要配置的，无非是我们配置 IP 的时候所需要的 IP 地址段、 子网掩码、网关地址、租期等。如果想使用 PXE，则需要配置 next-server，指向 PXE 服务器的地址， 另外要配置初始启动文件 filename。 

**这样 PXE 客户端启动之后，发送 DHCP 请求之后，除了能得到一个 IP 地址，还可以知道 PXE 服务器在 哪里，也可以知道如何从 PXE 服务器上下载某个文件，去初始化操作系统**。 

##### 解析 PXE 的工作过程 

接下来我们来**详细看一下 PXE 的工作过程**。 

首先，启动 PXE 客户端。第一步是通过 DHCP 协议告诉 DHCP Server，我刚来，一穷二白，啥都没有。DHCP Server 便租给它一个 IP 地址，**同时也给它 PXE 服务器的地址、启动文件 pxelinux.0**。 

其次，**PXE 客户端知道要去 PXE 服务器下载这个文件后，就可以初始化机器**。于是便开始下载，下载的时候使用的是 TFTP 协议。所以 PXE 服务器上，往往还需要有一个 TFTP 服务器。PXE 客户端向 TFTP 服务器请求下载这个文件，TFTP 服务器说好啊，于是就将这个文件传给它。 

然后，**PXE 客户端收到这个文件后，就开始执行这个文件。这个文件会指示 PXE 客户端，向 TFTP 服务 器请求计算机的配置信息 pxelinux.cfg。TFTP 服务器会给 PXE 客户端一个配置文件，里面会说内核在哪里、initramfs 在哪里。PXE 客户端会请求这些文件**。 

最后，启动 Linux 内核。一旦启动了操作系统，以后就啥都好办了。

![](/Users/nali/songyintao/SongYintao.github.io/img/pxe-follow.png)

### 三、从物理层到MAC层

#### 1. 第一层(物理层) 

使用路由器，是在第三层上。我们先从第一层物理层开始说。
**物理层能折腾啥?**现在的同学可能想不到，我们当时去学校配电脑的地方买网线，卖网线的师傅都会问，你的网线是要电脑连电脑啊，还是电脑连网口啊?

我们要的是电脑连电脑。这种方式就是一根网线，有两个头。一头插在一台电脑的网卡上，另一头插在 另一台电脑的网卡上。但是在当时，普通的网线这样是通不了的，所以水晶头要做交叉线，用的就是所 谓的1-3、2-6 交叉接法。 

水晶头的第 1、2 和第 3、6 脚，它们分别起着收、发信号的作用。将一端的 1 号和 3 号线、2 号和 6 号线互换一下位置，就能够在物理层实现一端发送的信号，另一端能收到。 

**当然电脑连电脑，除了网线要交叉，还需要配置这两台电脑的 IP 地址、子网掩码和默认网关**。这三个概 念上一节详细描述过了。要想两台电脑能够通信，这三项必须配置成为一个网络，可以一个是 192.168.0.1/24，另一个是 192.168.0.2/24，否则是不通的。 

等到第三个哥们也买了一台电脑，怎么把三台电脑连在一起呢?

先别说交换机，当时交换机也贵。有一个叫作**Hub**的东西，也就是**集线器**。**这种设备有多个口，可以将 宿舍里的多台电脑连接起来。但是，和交换机不同，集线器没有大脑，它完全在物理层工作。它会将自 己收到的每一个字节，都复制到其他端口上去**。**这是第一层物理层联通的方案**。 

#### 2. 第二层(数据链路层)

Hub 采取的是广播的模式，如果每一台电脑发出的包，宿舍的每个电脑都能收 到，那就麻烦了。这就需要解决几个问题: 

1. **这个包是发给谁的?谁应该接收?**

2. **大家都在发，会不会产生混乱?有没有谁先发、谁后发的规则?** 

3. **如果发送的时候出现了错误，怎么办?** 

   

这几个问题，都是第二层，数据链路层，也即 MAC 层要解决的问题。MAC的全称是Medium Access Contr**ol，即媒体访问控制。**控制什么呢?其实就是控制在往媒体上发数据的时候，谁先发、谁后发的问题。防止发生混乱。

这**解决的是第二个问题**。这个问题中的规则，学名叫**多路访问**。有很多算法可以解决这个问题。就像车管所管束马路上跑的车，能想的办法都想过了。

比如接下来这三种方式: 

 **方式一**:分多个车道。每个车一个车道，你走你的，我走我的。这在计算机网络里叫作**信道划分**;
 **方式二**:今天单号出行，明天双号出行，轮着来。这在计算机网络里叫作**轮流协议**;
 **方式三**:不管三七二十一，有事儿先出门，发现特堵，就回去。错过高峰再出。我们叫作**随机接入协议**。著名的以太网，用的就是这个方式。

解决了第二个问题，就是解决了媒体接入控制的问题，MAC 的问题也就解决好了。这和 MAC 地址没什 么关系。 

接下来要**解决第一个问题**:发给谁，谁接收?这里用到一个物理地址，叫作链路层地址。但是因为第二层主要解决媒体接入控制的问题，所以它常被称为MAC 地址。

解决第一个问题就牵扯到第二层的网络包格式。对于以太网，第二层的最开始，就是目标的 MAC 地址和源的MAC 地址。

![](/Users/nali/songyintao/SongYintao.github.io/img/mac-protocol.png)

​	接下来是类型，大部分的类型是 IP 数据包，然后 IP 里面包含 TCP、UDP，以及 HTTP 等，这都是里层 封装的事情。 

​	有了这个目标 MAC 地址，数据包在链路上广播，MAC 的网卡才能发现，这个包是给它的。MAC 的网 卡把包收进来，然后打开 IP 包，发现 IP 地址也是自己的，再打开 TCP 包，发现端口是自己，也就是 80，而 nginx 就是监听 80。 

​	于是将请求提交给 nginx，nginx 返回一个网页。然后将网页需要发回请求的机器。然后层层封装，最后到MAC 层。因为来的时候有源 MAC 地址，返回的时候，源 MAC 就变成了目标 MAC，再返给请求 的机器。 

​	**对于以太网，第二层的最后面是CRC，也就是循环冗余检测**。通过 XOR 异或的算法，来计算整个包是否 在发送的过程中出现了错误，主要**解决第三个问题**。 

​	这里还有一个没有解决的问题，**当源机器知道目标机器的时候，可以将目标地址放入包里面，如果不知道呢?**一个广播的网络里面接入了 N 台机器，我怎么知道每个 MAC 地址是谁呢?**这就是ARP 协议，也就是已知 IP 地址，求 MAC 地址的协议。**

![](/Users/nali/songyintao/SongYintao.github.io/img/arp-step1.png)

在一个局域网里面，当知道了 IP 地址，不知道 MAC 怎么办呢?靠“吼”。

![](/Users/nali/songyintao/SongYintao.github.io/img/arp-step2.png)

广而告之，发送一个广播包，谁是这个 IP 谁来回答。具体询问和回答的报文就像下面这样:

![](/Users/nali/songyintao/SongYintao.github.io/img/arp-step3.png)

为了避免每次都用 ARP 请求，**机器本地也会进行 ARP 缓存**。当然机器会不断地上线下线，IP 也可能会变，所以 **ARP 的 MAC 地址缓存过一段时间就会过期**。

一旦机器数目增多，问题就出现了。**因为 Hub 是广播 的，不管某个接口是否需要，所有的 Bit 都会被发送出去，然后让主机来判断是不是需要**。这种方式路 上的车少就没问题，车一多，产生冲突的概率就提高了。**而且把不需要的包转发过去，纯属浪费**。看来 Hub 这种不管三七二十一都转发的设备是不行了，需要点儿智能的。因为每个口都只连接一台电脑，这台电脑又不怎么换 IP 和 MAC 地址，**只要记住这台电脑的 MAC 地址，如果目标 MAC 地址不是这台电 脑的，这个口就不用转发了**。 

**谁能知道目标 MAC 地址是否就是连接某个口的电脑的 MAC 地址呢?这就需要一个能把 MAC 头拿下 来，检查一下目标 MAC 地址，然后根据策略转发的设备**，按第二节课中讲过的，这个设备显然是个二 层设备，我们称为**交换机。** 

交换机怎么知道每个口的电脑的 MAC 地址呢?**这需要交换机会学习。** 

一台 MAC1 电脑将一个包发送给另一台 MAC2 电脑，**当这个包到达交换机的时候，一开始交换机也不 知道 MAC2 的电脑在哪个口，所以没办法，它只能将包转发给出了来的那个口之外的其他所有的口**。但是，这个时候，交换机会干一件非常聪明的事情，就是**交换机会记住，MAC1 是来自一个明确的口**。以后有包的目的地址是 MAC1 的,直接发送到这个口就可以了。

​	当交换机作为一个关卡一样，**过了一段时间之后，就有了整个网络的一个结构了，这个时候，基本上不**
**用广播了，全部可以准确转发**。当然，每个机器的 IP 地址会变，所在的口也会变，因而**交换机上的学习的结果**，我们称为**转发表，是有一个过期时间的**。

​	我们来总结一下，有三个重点需要你记住:
第一，**MAC层是用来解决多路访问的堵车问题**的;
第二，**ARP 是通过吼的方式来寻找目标 MAC 地址的**，**吼完之后记住一段时间，这个叫作缓存**;
第三，**交换机是有 MAC 地址学习能力的，学完了它就知道谁在哪儿了，不用广播了**。



### 四、交换机和VLAN

#### 1.**拓扑结构是怎么形成的?** 

​	我们常见到的办公室大多是一排排的桌子，每个桌子都有网口，一排十几个座位就有十几个网口，一个楼层就会有几十个甚至上百个网口。如果算上所有楼层，这个场景自然比你宿舍里的复杂多了。具体哪里复杂呢?我来给你具体讲解。
​	首先，这个时候，**一个交换机肯定不够用，需要多台交换机，交换机之间连接起来，就形成一个稍微复杂的拓扑结构**。

![](/Users/nali/songyintao/SongYintao.github.io/img/交换机-step1.png)

​	我们先来看两台交换机的情形。两台交换机连接着三个局域网，每个局域网上都有多台机器。如果机器 1 只知道机器 4 的 IP 地址，当它想要访问机器 4，把包发出去的时候，它必须要知道机器 4 的 MAC 地 址。 

​	于是机器 1 发起广播，机器 2 收到这个广播，但是这不是找它的，所以没它什么事。**交换机 A 一开始是不知道任何拓扑信息的，在它收到这个广播后，采取的策略是，除了广播包来的方向外，它还要转发给其他所有的网口**。于是机器 3 也收到广播信息了，但是这和它也没什么关系。 

​	当然，**交换机 B 也是能够收到广播信息的，但是这时候它也是不知道任何拓扑信息的，因而也是进行广 播的策略，将包转发到局域网三**。这个时候，机器 4 和机器 5 都收到了广播信息。**机器 4 主动响应说，这是找我的，这是我的 MAC 地址。于是一个 ARP 请求就成功完成了**。 

​	在上面的过程中，交换机 A 和交换机 B 都是能够学习到这样的信息**:机器 1 是在左边这个网口的**。当了 解到这些拓扑信息之后，情况就好转起来。**当机器 2 要访问机器 1 的时候，机器 2 并不知道机器 1 的 MAC 地址**，所以机器 2 会发起一个 ARP 请求。**这个广播消息会到达机器 1，也同时会到达交换机 A**。 **这个时候交换机 A 已经知道机器 1 是不可能在右边的网口的，所以这个广播信息就不会广播到局域网二 和局域网三**。 

​	当机器 3 要访问机器1的时候，也需要发起一个广播的 ARP 请求。这个时候交换机 A 和交换机 B 都能够收到这个广播请求。**交换机 A 当然知道主机 A 是在左边这个网口的，所以会把广播消息转发到局域网 一。同时，交换机 B 收到这个广播消息之后，由于它知道机器 1 是不在右边这个网口的，所以不会将消息广播到局域网三**。 

#### 2.如何解决常见的环路问题?

​	这样看起来，两台交换机工作得非常好。随着办公室越来越大，交换机数目肯定越来越多。当整个拓扑结构复杂了，这么多网线，绕过来绕过去，不可避免地会出现一些意料不到的情况。其中常见的问题就是环路问题。

​	例如这个图，当两个交换机将两个局域网同时连接起来的时候。你可能会觉得，这样反而有了高可用性。但是却不幸地出现了环路。出现了环路会有什么结果呢?

![](/Users/nali/songyintao/SongYintao.github.io/img/交换机-环路.png)

​	我们来想象一下机器1访问机器2的过程。一开始，机器1并不知道机器2的MAC地址，所以它需要发起一个ARP的广播。广播到达机器2，机器2会把MAC地址返回来，看起来没有这 两个交换机什么事情。 

​	但是问题来了，这两个交换机还是都能够收到广播包的。交换机A一开始是不知道机器2在哪个局域网的，所以它会把广播消息放到局域网二，在局域网二广播的时候，交换机B右边 这个网口也是能够收到广播消息的。交换机B会将这个广播息信息发送到局域网一。局域网一的这个广播消息，又会到达交换机A左边的这个接口。交换机A这个时候还是不知道机 器2在哪个局域网，于是将广播包又转发到局域网二。左转左转左转，好像是个圈哦。 

**可能有人会说，当两台交换机都能够逐渐学习到拓扑结构之后，是不是就可以了?**

​	**别想了，压根儿学不会的。**机器1的广播包到达交换机A和交换机B的时候，本来两个交换机都学会了机器1是在局域网一的，但是当交换机A将包广播到局域网二之后，交换机B右边 的网口收到了来自交换机A的广播包。根据学习机制，**这彻底损坏了交换机B的三观**，刚才机器1还在左边的网口呢，怎么又出现在右边的网口呢?哦，那肯定是机器1换位置了，于是就误会了，交换机B就学会了，机器1是从右边这个网口来的，把刚才学习的那一条清理掉。同理，交换机A右边的网口，也能收到交换机B转发过来的广播包，同样也误会了，于是也学会了，机器1从右边的网口来，不是从左边的网口来。 

​	然而当广播包从左边的局域网一广播的时候，两个交换机再次刷新三观，原来机器1是在左边的，过一会儿，又发现不对，是在右边的，过一会，又发现不对，是在左边的。 这还是一个包转来转去，每台机器都会发广播包，交换机转发也会复制广播包，当广播包越来越多的时候，按照上一节讲过一个共享道路的算法，也就是**路会越来越堵，最后谁也别想走**。所以，必须有一个方法解决环路的问题，怎么破除环路呢?



#### 3. STP协议中那些难以理解的概念

​	在数据结构中，有一个方法叫作**最小生成树**。**有环的我们常称为图**。**将图中的环破了，就生成了树**。在计算机网络中，**生成树的算法叫作STP**，全称**Spanning Tree Protocol**。 

​	STP协议比较复杂，一开始很难看懂，但是其实这是一场血雨腥风的武林比武或者华山论剑，最终决出五岳盟主的方式。 

![](/Users/nali/songyintao/SongYintao.github.io/img/stp.png)

在STP协议里面有很多概念，译名就非常拗口，但是我一作比喻，你很容易就明白了。

-  **Root Bridge**，也就是**根交换机**。这个比较容易理解，可以比喻为“掌门”交换机，是某棵树的老大，是掌门，最大的大哥。 

- **Designated Bridges**，有的翻译为**指定交换机**。这个比较难理解，可以想像成一个“小弟”，对于树来说，就是一棵树的树枝。所谓“指定”的意思是，我拜谁做大哥，其他交换机通 过这个交换机到达根交换机，也就相当于拜他做了大哥。这里注意是树枝，不是叶子，因为叶子往往是主机。 

- **Bridge Protocol Data Units (BPDU)** ，**网桥协议数据单元**。可以比喻为**“相互比较实力”的协议**。行走江湖，比的就是武功，拼的就是实力。当两个交换机碰见的时候，也就是相 连的时候，就需要互相比一比内力了。BPDU只有掌门能发，**已经隶属于某个掌门的交换机只能传达掌门的指示**。 

- **Priority Vector**，**优先级向量**。可以比喻为实力 (值越小越牛)。实力是啥?就是一组ID数目，[**Root Bridge ID**, **Root Path Cost**, **Bridge ID**, **and Port ID**]。为什么这样设计呢?这是因为要看怎么来比实力。先看Root Bridge ID。拿出老大的ID看看，发现掌门一样，那就是师兄弟;再比Root Path Cost，也即我距离我的老大的距离，也就是拿和掌门关系比，看同一个门派内谁和老大的关系最铁；最后比 Bridge ID，比我自己的ID，拿自己的本事比。



**STP的工作过程**：

- 一开始，江湖纷争，异常混乱。大家都觉得自己是掌门，谁也不服谁。于是，所有的交换机都认为自己是掌门，每个网桥都被分配了一个ID。这个ID里有管理员分配的优先级，当然网络管理员知道哪些交换机贵，哪些交换机好，就会**给它们分配高的优先级**。这种交换机生下来武功就很高，起步就是乔峰。

​	![](/Users/nali/songyintao/SongYintao.github.io/img/stp-1.png)

- 既然都是掌门，互相都连着网线，就互相发送BPDU来比功夫呗。这一比就发现，有人是岳不群，有人是封不平，赢的接着当掌门，输的就只好做小弟了。当掌门的还会继续发BPDU，而输的人就没有机会了。它们只有在收到掌门发的BPDU的时候，转发一下，表示服从命令。

   ![](/Users/nali/songyintao/SongYintao.github.io/img/stp-2.png)

- 数字表示优先级。就像这个图，5和6碰见了，6的优先级低，所以乖乖做小弟。于是一个小门派形成，5是掌门，6是小弟。其他诸如1-7、2-8、3-4这样的小门派，也诞生了。于是江湖出现了很多小的门派，小的门派，接着合并。

**合并的过程会出现以下四种情形，我分别来介绍**。

**情形一：掌门遇到掌门**

​	当5碰到了1，掌门碰见掌门，1觉得自己是掌门，5也刚刚跟别人PK完成为掌门。这俩掌门比较功夫，最终1胜出。于是输掉的掌门5就会率领所有的小弟归顺。结果就是1成为大掌门。

![](/Users/nali/songyintao/SongYintao.github.io/img/stp-3.png)

**情形二：同门相遇**

​	同门相遇可以是掌门与自己的小弟相遇，这说明存在“环”了。这个小弟已经通过其他门路拜在你门下，结果你还不认识，就PK了一把。结果掌门发现这个小弟功夫不错，不应该级别这么低，就把它招到门下亲自带，那这个小弟就相当于升职了。

​	我们再来看，假如1和6相遇。6原来就拜在1的门下，只不过6的上司是5，5的上司是1。1发现，6距离我才只有2，比从5这里过来的5（=4+1）近多了，那6就直接汇报给我吧。于是，5和6分别汇报给1。

![](/Users/nali/songyintao/SongYintao.github.io/img/stp-4.png)


​	同门相遇还可以是小弟相遇。这个时候就要比较谁和掌门的关系近，当然近的当大哥。刚才5和6同时汇报给1了，后来5和6再比较功夫的时候发现，5你直接汇报给1距离是4，如果5汇报给6再汇报给1，距离只有2+1=3，所以5干脆拜6为上司。

**情形三：掌门与其他帮派小弟相遇**

​	小弟拿本帮掌门和这个掌门比较，赢了，这个掌门拜入门来。输了，会拜入新掌门，并且逐渐拉拢和自己连接的兄弟，一起弃暗投明。

 ![](/Users/nali/songyintao/SongYintao.github.io/img/stp-5.png)

​	例如，2和7相遇，虽然7是小弟，2是掌门。就个人武功而言，2比7强，但是7的掌门是1，比2牛，所以没办法，2要拜入7的门派，并且连同自己的小弟都一起拜入。

**情形四：不同门小弟相遇**

​	各自拿掌门比较，输了的拜入赢的门派，并且逐渐将与自己连接的兄弟弃暗投明。

![](/Users/nali/songyintao/SongYintao.github.io/img/stp-6.png)

​	例如，5和4相遇。虽然4的武功好于5，但是5的掌门是1，比4牛，于是4拜入5的门派。后来当3和4相遇的时候，3发现4已经叛变了，4说我现在老大是1，比你牛，要不你也来吧， 于是3也拜入1。

​	最终，生成一棵树，武林一统，天下太平。但是天下大势，分久必合，合久必分，天下统一久了，也会有相应的问题。

#### 4.**如何解决广播问题和安全问题？**

​	毕竟机器多了，交换机也多了，就算交换机比Hub智能一些，但是还是难免有广播的问题，一大波机器，相关的部门、不相关的部门，**广播一大堆，性能就下来了**。就像一家公司， 创业的时候，一二十个人，坐在一个会议室，有事情大家讨论一下，非常方便。但是如果变成了50个人，全在一个会议室里面吵吵，就会乱的不得了。

​	你们公司有不同的部门，有的部门需要保密的，比如人事部门，肯定要讨论升职加薪的事儿。由于在同一个广播域里面，很多包都会在一个局域网里面飘啊飘，碰到了一个会抓包的程序员，就能抓到这些包，如果没有加密，就能看到这些敏感信息了。还是上面的例子，50个人在一个会议室里面七嘴八舌的讨论，其中有两个HR，那他们讨论的问题，肯定被其他人偷偷听走了。

​	那咋办，分部门，分会议室呗。那我们就来看看怎么分。

​	有两种分的方法，一个是**物理隔离**。每个部门设一个单独的会议室，对应到网络方面，就是**每个部门有单独的交换机，配置单独的子网，这样部门之间的沟通就需要路由器了**。路由器咱们还没讲到，以后再说。这样的问题在于，有的部门人多，有的部门人少。人少的部门慢慢人会变多，人多的部门也可能人越变越少。

​	如果每个部门有单独的交换机，口多了浪费，少了又不够用。

​	另外一种方式是**虚拟隔离**，就是用我们常说的VLAN，或者叫**虚拟局域网**。使用VLAN，一个交换机上会连属于多个局域网的机器，那交换机怎么区分哪个机器属于哪个局域网呢？

![](/Users/nali/songyintao/SongYintao.github.io/img/vlan-1.png)

​	我们只需要**在原来的二层的头上加一个TAG，里面有一个VLAN ID，一共12位**。为什么是12位呢?因为12位可以划分**4096个VLAN。这样是不是还不够啊**。现在的情况证明，目前云计算厂商里面绝对不止4096个用户。当然每个用户需要一个VLAN了啊，怎么办呢，这个我们在后面的章节再说。

​	如果我们买的交换机是支持VLAN的，**当这个交换机把二层的头取下来的时候，就能够识别这个VLAN ID**。这样**只有相同VLAN的包，才会互相转发**，不同VLAN的包，是看不到的。
​	这样广播问题和安全问题就都能够解决了。

![](/Users/nali/songyintao/SongYintao.github.io/img/vlan-2.png)

​	我们可以设置交换机每个口所属的VLAN。如果某个口坐的是程序员，他们属于VLAN 10;如果某个口坐的是人事，他们属于VLAN 20;如果某个口坐的是财务，他们属于VLAN30。这样，财务发的包，交换机只会转发到VLAN 30的口上。程序员啊，你就监听VLAN 10吧，里面除了代码，啥都没有。

​	而且对于交换机来讲，每个VLAN的口都是可以重新设置的。一个财务走了，把他所在的作为的口从VLAN 30移除掉，来了一个程序员，坐在财务的位置上，就把这个口设置 为VLAN 10，十分灵活。 

​	有人会问**交换机之间怎么连接呢?**将两个交换机连接起来的口应该设置成什么VLAN呢?**对于支持VLAN的交换机，有一种口叫作Trunk 口。它可以转发属于任何VLAN的口。交换机之间可以通过这种口相互连接**。 

#### 五、Traceroute：ICMP协议---探查

**Traceroute**:差错报文类型的使用 那其他的类型呢?是不是只有真正遇到错误的时候，才能收到呢?那也不是，有一个程序 Traceroute，是个“大骗子”。它会使用 ICMP 的规则，故意制造一些能够产生错误的场景。 

​	所以，Traceroute 的第一个作用就是故意设置特殊的 TTL，来追踪去往目的地时沿途经过的路由器。 Traceroute 的参数指向某个目的 IP 地址，它会发送一个 UDP 的数据包。将 TTL 设置成 1，也就是说一 旦遇到一个路由器或者一个关卡，就表示它“牺牲”了。 

​	如果中间的路由器不止一个，当然碰到第一个就“牺牲”。于是，返回一个 ICMP 包，也就是网络差错 包，类型是时间超时。那大军前行就带一顿饭，试一试走多远会被饿死，然后找个哨探回来报告，那我 就知道大军只带一顿饭能走多远了。 

​	接下来，将 TTL 设置为 2。第一关过了，第二关就“牺牲”了，那我就知道第二关有多远。如此反复， 直到到达目的主机。这样，Traceroute 就拿到了所有的路由器 IP。当然，有的路由器压根不会回这个 ICMP。这也是 Traceroute 一个公网的地址，看不到中间路由的原因。 

​	怎么知道 UDP 有没有到达目的主机呢?Traceroute 程序会发送一份 UDP 数据报给目的主机，但它会 选择一个不可能的值作为 UDP 端口号(大于 30000)。当该数据报到达时，将使目的主机的 UDP 模块 产生一份“端口不可达”错误 ICMP 报文。如果数据报没有到达，则可能是超时。 

​	这就相当于故意派人去西天如来那里去请一本《道德经》，结果人家信佛不信道，消息就会被打出来。 被打的消息传回来，你就知道西天是能够到达的。为什么不去取《心经》呢?因为 UDP 是无连接的。也 就是说这人一派出去，你就得不到任何音信。你无法区别到底是半路走丢了，还是真的信佛遁入空门 了，只有让人家打出来，你才会得到消息。 

​	**Traceroute 还有一个作用是故意设置不分片，从而确定路径的 MTU**。要做的工作首先是发送分组，并 设置“不分片”标志。发送的第一个分组的长度正好与出口 MTU 相等。如果中间遇到窄的关口会被卡 住，会发送 ICMP 网络差错包，类型为“需要进行分片但设置了不分片位”。其实，这是人家故意的好 吧，每次收到 ICMP“不能分片”差错时就减小分组的长度，直到到达目标主机。 

**ICMP** 相当于网络世界的侦察兵。

我讲了两种类型的 ICMP 报文，一种是主动探查的查询报文，一种异常报告的差错报文;
**ping** 使用**查询报**文，**Traceroute** 使用**差错报文**。



### 六、网关



世界这么大，我想出网关:欧洲十国游与玄奘西行



### 七、路由协议:西出网关无故人，敢问路在何方

​	俗话说得好，在家千日好，出门一日难。网络包一旦出了网关，就像玄奘西行一样踏上了江湖漂泊的路。
​	上一节我们描述的是一个相对简单的情形。出了网关之后，只有一条路可以走。但是，网络世界复杂得多，**一旦出了网关，会面临着很多路由器，有很多条道路可以选**。**如何选择一个更快速的道路求取真经呢?**这里面还有很多门道可以讲。

#### 1. **如何配置路由?** 

​	通过上一节的内容，你应该已经知道，**路由器就是一台网络设备，它有多张网卡**。**当一个入口的网络包送到路由器时，它会根据一个本地的转发信息库，来决定如何正确地转发流量。**这个转发信息库通常被称为**<u>路由表</u>**。
​	一张路由表中会有多条路由规则。每一条规则至少包含这三项信息。

- **目的网络**:这个包想去哪儿?
-  **出口设备**:将包从哪个口扔出去?
-  **下一跳网关**:下一个路由器的地址。

通过 **route** 命令和 **ip route** 命令都可以进行查询或者配置。 

​	例如，我们设置` ip route add 10.176.48.0/20 via 10.173.32.1 dev eth0`，就说明要去 `10.176.48.0/20` 这个目标网络，要从 **eth0** 端口出去，经过 `10.173.32.1`。 

​	上一节的例子中，网关上的路由策略就是按照这三项配置信息进行配置的。**这种配置方式的一个核心思想是:根据目的 IP 地址来配置路由**。	

#### 2.如何配置策略路由? 

​	当然，在真实的复杂的网络环境中，**除了可以根据目的 ip 地址配置路由外，还可以根据多个参数来配置路由**，这就称为**策略路由**。 

​	**可以配置多个路由表，可以根据源 IP 地址、入口设备、TOS 等选择路由表，然后在路由表中查找路由**。 这样可以使得来自不同来源的包走不同的路由。 

​	例如，我们设置: 

```shell
ip rule add from 192.168.1.0/24 table 10
ip rule add from 192.168.2.0/24 table 20
```

​	表示从 192.168.1.10/24 这个网段来的，使用 table 10 中的路由表，而从 192.168.2.0/24 网段来的， 使用 table20 的路由表。 

​	在一条路由规则中，也可以走多条路径。例如，在下面的路由规则中:

```shell
ip route add default scope global nexthop via 100.100.100.1 weight 1 nexthop via 200.200.200.1 weight 2
```

​	下一跳有两个地方，分别是 100.100.100.1 和 200.200.200.1，权重分别为 1 比 2。

​	默认的路由走慢的，谁让你不付钱。
​	上面说的都是静态的路由，一般来说网络环境简单的时候，在自己的可控范围之内，自己捣鼓还是可以的。但是有时候网络环境复杂并且多变，如果总是用静态路由，一旦网络结构发生变化，让网络管理员手工修改路由太复杂了，因而需要动态路由算法。



##### 动态路由算法

​	使用动态路由路由器，可以根据路由协议算法生成动态路由表，随网络运行状况的变化而变化。那路由算法是什么样的呢?
​	我们可以想象唐僧西天取经，需要解决两大问题，一个是在每个国家如何找到正确的路，去换通关文牒、吃饭、休息;一个是在国家之间，野外行走的时候，如何找到正确的路、水源的问题。

​	![](/Users/nali/songyintao/SongYintao.github.io/img/route-1.png)

​	无论是一个国家内部，还是国家之间，**我们都可以将复杂的路径，抽象为一种叫作图的数据结构**。至于
唐僧西行取经，肯定想走得路越少越好，道路越短越好，因而这就转化成为如何在途中找到最短路径的问题。

​	咱们在大学里面学习计算机网络与数据结构的时候，知道**求最短路径常用的有两种方法**，一种是**Bellman-Ford** 算法，一种是 **Dijkstra** 算法。在**<u>计算机网络中基本也是用这两种方法计算</u>**的。	

1. **距离矢量路由算法**

   

​          第一大类的算法称为**距离矢量路由**(distance vector routing)。它是基于 Bellman-Ford 算法的。 这种算法的**基本思路是，每个路由器都保存一个路由表，包含多行，每行对应网络中的一个路由器，每一行包含两部分信息，一个是要到目标路由器，从那条线出去，另一个是到目标路由器的距离。**由此可以看出，每个路由器都是知道全局信息的。那这个信息如何更新呢?每个路由器都知道自己和邻居之间的距离，每过几秒，每个路由器都将自己所知的到达所有的路由器的距离告知邻居，每个路由器也能从邻居那里得到相似的信息。

​	每个路由器根据新收集的信息，计算和其他路由器的距离，比如自己的一个邻居距离目标路由器的距离是 M，而自己距离邻居是 x，则自己距离目标路由器是 x+M。 

​	**这个算法比较简单，但是还是有问题。**
​	第一个问题就是好消息传得快，坏消息传得慢。如果有个路由器加入了这个网络，它的邻居就能很快发现它，然后将消息广播出去。要不了多久，整个网络就都知道了。但是一旦一个路由器挂了，挂的消息是没有广播的。当每个路由器发现原来的道路到不了这个路由器的时候，感觉不到它已经挂了，而是试图通过其他的路径访问，直到试过了所有的路径，才发现这个路由器是真的挂了。

​	原来的网络包括两个节点，B 和 C。A 加入了网络，它的邻居 B 很快就发现 A 启动起来了。于是它将自 己和 A 的距离设为 1，同样 C 也发现 A 起来了，将自己和 A 的距离设置为 2。但是如果 A 挂掉，情况 就不妙了。B 本来和 A 是邻居，发现连不上 A 了，但是 C 还是能够连上，只不过距离远了点，是 2，于 是将自己的距离设置为 3。殊不知 C 的距离 2 其实是基于原来自己的距离为 1 计算出来的。C 发现自己 也连不上 A，并且发现 B 设置为 3，于是自己改成距离 4。依次类推，数越来越大，直到超过一个阈 值，我们才能判定 A 真的挂了。 

​	这个道理有点像有人走丢了。当你突然发现找不到这个人了。于是你去学校问，是不是在他姨家呀?找到他姨家，他姨说，是不是在他舅舅家呀?他舅舅说，是不是在他姥姥家呀?他姥姥说，是不是在学校呀?总归要问一圈，或者是超过一定的时间，大家才会认为这个人的确走丢了。如果这个人其实只是去见了一个谁都不认识的网友去了，当这个人回来的时候，只要他随便见到其中的一个亲戚，这个亲戚就会拉着他到他的家长那里，说你赶紧回家，你妈都找你一天了。

​	**这种算法的第二个问题**是，**每次发送的时候，要发送整个全局路由表**。网络大了，谁也受不了，所以最 早的路由协议 RIP 就是这个算法。**它适用于小型网络(小于 15 跳)。当网络规模都小的时候，没有问题**。现在一个数据中心内部路由器数目就很多，因而不适用了。 

所以上面的两个问题**，限制了距离矢量路由的网络规模**。



2. **链路状态路由算法**

   第二大类算法是**链路状态路由(link state routing)，基于 Dijkstra 算法**。 

这种算法的**基本思路**是:当一个路由器启动的时候，首先是发现邻居，向邻居 say hello，邻居都回复。 然后计算和邻居的距离，发送一个 echo，要求马上返回，除以二就是距离。然后将自己和邻居之间的链 路状态包广播出去，发送到整个网络的每个路由器。**这样每个路由器都能够收到它和邻居之间的关系的信息。因而，每个路由器都能在自己本地构建一个完整的图，然后针对这个图使用 Dijkstra 算法，找到 两点之间的最短路径**。 

​	**不像距离距离矢量路由协议那样，更新时发送整个路由表。链路状态路由协议只广播更新的或改变的网络拓扑，这使得更新信息更小，节省了带宽和 CPU 利用率**。而且一旦一个路由器挂了，它的邻居都会广播这个消息，**可以使得坏消息迅速收敛**。 



##### 1. 动态路由协议

**1. 基于链路状态路由算法的 OSPF**

​	**OSPF(Open Shortest Path First，开放式最短路径优先)**就是这样一个基于链路状态路由协议，广泛应用在数据中心中的协议。**由于主要用在数据中心内部，用于路由决策，因而称为内部网关协议** (Interior Gateway Protocol，简称**IGP**)。 

​	**内部网关协议的重点就是找到最短的路径**。在一个组织内部，路径最短往往最优。**当然有时候 OSPF 可以发现多个最短的路径，可以在这多个路径中进行负载均衡，这常常被称为等价路由**。 

![](/Users/nali/songyintao/SongYintao.github.io/img/route-2.png)

​	这一点非常重要。**有了等价路由，到一个地方去可以有相同的两个路线，可以分摊流量，还可以当一条路不通的时候，走另外一条路。**这个在后面我们讲数据中心的网络的时候，**一般应用的接入层会有负载均衡 LVS。它可以和 OSPF 一起，实现高吞吐量的接入层设计**。

​	有了内网的路由协议，在一个国家内，唐僧可以想怎么走怎么走了，两条路选一条也行。



**2.基于距离矢量路由算法的 BGP**

​	但是外网的路由协议，也即国家之间的，又有所不同。我们称为**外网路由协议**(Border Gateway Protocol，简称**BGP**)。 

​	在一个国家内部，有路当然选近的走。但是国家之间，不光远近的问题，还有政策的问题。例如，唐僧去西天取经，有的路近。但是路过的国家看不惯僧人，见了僧人就抓。例如灭法国，连光头都要抓。这样的情况即便路近，也最好绕远点走。

​	**对于网络包同样，每个数据中心都设置自己的 Policy。**例如，哪些外部的 IP 可以让内部知晓，哪些内部的 IP 可以让外部知晓，哪些可以通过，哪些不能通过。这就好比，虽然从我家里到目的地最近，但是不能谁都能从我家走啊! 

​	**在网络世界，这一个个国家成为自治系统AS(Autonomous System)**。

自治系统分几种类型。

 **Stub AS:**对外只有一个连接。这类 AS 不会传输其他 AS 的包。例如，个人或者小公司的网络。 

**Multihomed AS:**可能有多个连接连到其他的 AS，但是大多拒绝帮其他的 AS 传输包。例如一些大 公司的网络。 

**Transit AS**:有多个连接连到其他的 AS，并且可以帮助其他的 AS 传输包。例如主干网。 **每个自治系统都有边界路由器，通过它和外面的世界建立联系**。 

![](/Users/nali/songyintao/SongYintao.github.io/img/route-3.png)

**BGP 又分为两类，eBGP 和 iBGP**。

​	自治系统间，**边界路由器之间使用 eBGP 广播路由**。

​	内部网络也需要访问其他的自治系统。**边界路由器如何将 BGP 学习到的路由导入到内部网络呢?**就是通过运行 **iBGP**， **使得内部的路由器能够找到到达外网目的地的最好的边界路由器**。 

​	**BGP 协议使用的算法是路径矢量路由协议(path-vector protocol)。它是距离矢量路由协议的升级版**。 

​	前面说了距离矢量路由协议的缺点。其中一个是收敛慢。在 BGP 里面，除了下一跳 hop 之外，还包括了自治系统 AS 的路径，从而可以避免坏消息传的慢的问题，也即上面所描述的，B 知道 C 原来能够到达 A，是因为通过自己，一旦自己都到达不了 A 了，就不用假设 C 还能到达 A 了。 

​	另外，**在路径中将一个自治系统看成一个整体，不区分自治系统内部的路由器，这样自治系统的数目是非常有限的。**就像大家都能记住出去玩，从中国出发先到韩国然后到日本，只要不计算细到具体哪一站，就算是发送全局信息，也是没有问题的。

**好了，这一节就到这里了，我来做个总结:**

1. 路由分**静态路由**和**动态路由**，静态路由可以配置复杂的策略路由，控制转发策略;

2. 动态路由主流算法有两种，**距离矢量算法**和**链路状态算**法。基于两种算法产生两种协议，**BGP 协议**和 **OSPF 协议**。 



### 八、UDP协议：因性善而简单，难免碰到城会玩

​	讲完了 IP 层以后，接下来我们开始讲传输层。传输层里比较重要的两个协议，一个是 TCP，一个是UDP。对于不从事底层开发的人员来讲，或者对于开发应用的人来讲，最常用的就是这两个协议。由于面试的时候，这两个协议经常会被放在一起问，因而我在讲的时候，也会结合着来讲。

#### **1.TCP 和 IP 有哪些区别?**
​	 一般面试的时候我问这两个协议的区别，大部分人会回答，TCP 是**面向连接**的，UDP 是**面向无连接**的。 

​	**什么叫面向连接，什么叫无连接呢?**在互通之前，**面向连接的协议会先建立连接**。例如，TCP 会三次握 手，而 UDP 不会。为什么要建立连接呢?你 TCP 三次握手，我 UDP 也可以发三个包玩玩，有什么区别吗? 

​	**所谓的建立连接，是为了在客户端和服务端维护连接，而<u>建立一定的数据结构来维护双方交互的状态</u>，用这样的数据结构来保证所谓的面向连接的特性。**

​	例如，**TCP 提供可靠交付。通过 TCP 连接传输的数据，无差错、不丢失、不重复、并且按序到达。我们都知道 IP 包是没有任何可靠性保证的，一旦发出去，就像西天取经，走丢了、被妖怪吃了，都只能随它去。但是 TCP 号称能做到那个连接维护的程序做的事情，这个下两节我会详细描述。而UDP 继承了 IP 包的特性，不保证不丢失，不保证按顺序到达**。 

​	再如，**TCP 是面向字节流的**。发送的时候发的是一个流，没头没尾。IP 包可不是一个流，而是一个个的IP包。**之所以变成了流，这也是 TCP 自己的状态维护做的事情。而UDP 继承了 IP 的特性，基于数据报的，一个一个地发，一个一个地收**。

​	还有**TCP 是可以有拥塞控制的。它意识到包丢弃了或者网络的环境不好了，就会根据情况调整自己的行为，看看是不是发快了，要不要发慢点。UDP 就不会，应用让我发，我就发，管它洪水滔天**。

​	因而**TCP 其实是一个有状态服务**，通俗地讲就是有脑子的，**里面精确地记着发送了没有，接收到没有， 发送到哪个了，应该接收哪个了，错一点儿都不行**。而**UDP 则是无状态服务**。通俗地说是没脑子的，天 真无邪的，发出去就发出去了。 

​	我们可以这样比喻，如果 **<u>MAC 层定义了本地局域网的传输行为</u>**，**<u>IP 层定义了整个网络端到端的传输行为</u>**，**这两层基本定义了这样的基因**:**<u>网络传输是以包为单位的</u>**，**二层叫帧，网络层叫包，传输层叫段**。 我们笼统地称为包。包单独传输，自行选路，在不同的设备封装解封装，不保证到达。基于这个基因， 生下来的孩子 UDP 完全继承了这些特性，几乎没有自己的思想。 

#### 2. UDP包头是什么样的? 我们来看一下 UDP 包头

​	前面章节我已经讲过包的传输过程，这里不再赘述。**当我发送的 UDP 包到达目标机器后，发现 MAC地址匹配，于是就取下来，将剩下的包传给处理 IP 层的代码。把 IP 头取下来，发现目标 IP 匹配，接下来呢?**这里面的数据包是给谁呢? 

​	发送的时候，我知道我发的是一个 UDP 的包，收到的那台机器咋知道的呢?所以**在 IP头里面有个 8 位协议，这里会存放，数据里面到底是 TCP 还是 UDP，当然这里是 UDP**。于是，如果我们知道 UDP 头 的格式，就能从数据里面，将它解析出来。解析出来以后呢?数据给谁处理呢? 

​	**处理完传输层的事情，内核的事情基本就干完了，里面的数据应该交给应用程序自己去处理，可是一台机器上跑着这么多的应用程序，应该给谁呢?**

​	无论**应用程序写的使用 TCP 传数据，还是 UDP 传数据，都要监听一个端口**。**正是这个端口，用来区分应用程序，要不说端口不能冲突呢**。两个应用监听一个端口，到时候包给谁呀?所以，按理说，无论是 TCP 还是 UDP 包头里面应该有端口号，根据端口号，将数据交给相应的应用程序。 

![](/Users/nali/songyintao/SongYintao.github.io/img/udp-1.png)

​	当我们看到 UDP 包头的时候，发现的确有端口号，有源端口号和目标端口号。因为是两端通信嘛，这很好理解。但是你还会发现，UDP 除了端口号，再没有其他的了。和下两节要讲的 TCP 头比起来，这个简直简单得一塌糊涂啊!

  #### 3. UDP 的三大特点



​	**第一**，沟通简单，不需要一肚子花花肠子(大量的数据结构、处理逻辑、包头字段)。前提是它相信网络世界是美好的，秉承性善论，相信网络通路默认就是很容易送达的，不容易被丢弃的。
​	**第二**，轻信他人。它不会建立连接，虽然有端口号，但是监听在这个地方，谁都可以传给他数据，他也可以传给任何人数据，甚至可以同时传给多个人数据。
​	**第三**，愣头青，做事不懂权变。不知道什么时候该坚持，什么时候该退让。它不会根据网络的情况进行发包的拥塞控制，无论网络丢包丢成啥样了，它该怎么发还怎么发。





#### 4.  UDP 的三大使用场景



​	**第一，需要资源少，在网络情况比较好的内网，或者对于丢包不敏感的应用。**这很好理解，就像如果你是领导，你会让你们组刚毕业的小朋友去做一些没有那么难的项目，打一些没有那么难的客户，或者做一些失败了也能忍受的实验性项目。

​	我们在第四节讲的 DHCP 就是基于 UDP 协议的。一般的获取 IP 地址都是内网请求，而且一次获取不到 IP 又没事，过一会儿还有机会。我们讲过 PXE 可以在启动的时候自动安装操作系统，操作系统镜像的下 载使用的 TFTP，这个也是基于 UDP 协议的。在还没有操作系统的时候，客户端拥有的资源很少，不适 合维护一个复杂的状态机，而是因为是内网，一般也没啥问题。 

​	**第二，不需要一对一沟通，建立连接，而是可以广播的应用。**咱们小时候人都很简单，大家在班级里面，谁成绩好，谁写作好，应该表扬谁惩罚谁，谁得几个小红花都是当着全班的面讲的，公平公正公开。长大了人心复杂了，薪水、奖金要背靠背，和员工一对一沟通。

​	**UDP 的不面向连接的功能，可以使得可以承载广播或者多播的协议。**DHCP 就是一种广播的形式，就是 基于 UDP 协议的，而广播包的格式前面说过了。 

​	对于多播，我们在讲 IP 地址的时候，讲过一个 D 类地址，也即组播地址，使用这个地址，可以将包组播给一批机器。**当一台机器上的某个进程想监听某个组播地址的时候，需要发送 IGMP 包，所在网络的 路由器就能收到这个包，知道有个机器上有个进程在监听这个组播地址。当路由器收到这个组播地址的 时候，会将包转发给这台机器，这样就实现了跨路由器的组播**。 

​	**在后面云中网络部分，有一个协议 VXLAN，也是需要用到组播，也是基于 UDP 协议的。** 

​	**第三，需要处理速度快，时延低，可以容忍少数丢包，但是要求即便网络拥塞，也毫不退缩，一往无前的时候。**记得曾国藩建立湘军的时候，专门招出生牛犊不怕虎的新兵，而不用那些“老油条”的八旗兵，就是因为八旗兵经历的事情多，遇到敌军不敢舍死忘生。

​	同理，UDP 简单、处理速度快，不像 TCP 那样，操这么多的心，各种重传啊，保证顺序啊，前面的不收到，后面的没法处理啊。不然等这些事情做完了，时延早就上去了。而 TCP 在网络不好出现丢包的时候，拥塞控制策略会主动的退缩，降低发送速度，这就相当于本来环境就差，还自断臂膀，用户本来就卡，这下更卡了。 

​	**当前很多应用都是要求低时延的，它们可不想用 TCP 如此复杂的机制，而是想根据自己的场景，实现自己的可靠和连接保证。**例如，如果应用自己觉得，有的包丢了就丢了，没必要重传了，就可以算了，有的比较重要，则应用自己重传，而不依赖于 TCP。有的前面的包没到，后面的包到了，那就先给客户展示后面的嘛，干嘛非得等到齐了呢?如果网络不好，丢了包，那不能退缩啊，要尽快传啊，速度不能降 下来啊，要挤占带宽，抢在客户失去耐心之前到达。 



​	**由于 UDP 十分简单，基本啥都没做，也就给了应用“城会玩”的机会。**就像在和平年代，每个人应该有 独立的思考和行为，应该可靠并且礼让;但是如果在战争年代，往往不太需要过于独立的思考，而需要 士兵简单服从命令就可以了。 

​	曾国藩说哪支部队需要诱敌牺牲，也就牺牲了，相当于包丢了就丢了。两军狭路相逢的时候，曾国藩说上，没有带宽也要上，这才给了曾国藩运筹帷幄，城会玩的机会。**同理如果你实现的应用需要有自己的连接策略，可靠保证，时延要求，使用 UDP，然后再应用层实现这些是再好不过了**。 



#### 5. 基于UDP的城会玩的五个例子 我列举几种“城会玩”的例子



#####  城会玩一: 网页或者  PP 的访问 

​	原来访问网页和手机 APP 都是基于 HTTP 协议的。HTTP 协议是基于 TCP 的，建立连接都需要多次交互，对于时延比较大的目前主流的移动互联网来讲，建立一次连接需要的时间会比较长，然而既然是移动中，TCP 可能还会断了重连，也是很耗时的。而且目前的 HTTP 协议，往往采取多个数据通道共享一个连接的情况，这样本来为了加快传输速度，但是 TCP 的严格顺序策略使得哪怕共享通道，前一个不来，后一个和前一个即便没关系，也要等着，时延也会加大。 

​	而**QUIC**(全称**Quick UDP Internet Connections**，快速 UDP 互联网连接)是 **Google 提出的一种基于 UDP 改进的通信协议，其目的是降低网络通信的延迟，提供更好的用户互动体验**。 

​	QUIC 在应用层上，会自己实现快速连接建立、减少重传时延，自适应拥塞控制，是应用层“城会玩”的代表。这一节主要是讲 UDP，QUIC 我们放到应用层去讲。 



##### 城会玩二:流媒体的协议 

​	现在直播比较火，**直播协议多使用 RTMP**，这个协议我们后面的章节也会讲，而**这个 RTMP 协议也是基 于 TCP 的**。TCP 的严格顺序传输要保证前一个收到了，下一个才能确认，如果前一个收不到，下一个就 算包已经收到了，在缓存里面，也需要等着。**<u>对于直播来讲，这显然是不合适的，因为老的视频帧丢了其实也就丢了，就算再传过来用户也不在意了，他们要看新的了，如果老是没来就等着，卡顿了，新的也看不了，那就会丢失客户，所以直播，实时性比较比较重要，宁可丢包，也不要卡顿的。</u>** 

​	另外，对于丢包，其实对于视频播放来讲，有的包可以丢，有的包不能丢，因为视频的连续帧里面，有的帧重要，有的不重要，如果必须要丢包，隔几个帧丢一个，其实看视频的人不会感知，但是如果连续丢帧，就会感知了，因而在网络不好的情况下，应用希望选择性的丢帧。

​	**还有就是当网络不好的时候，TCP 协议会主动降低发送速度，这对本来当时就卡的看视频来讲是要命的，应该应用层马上重传，而不是主动让步。**因而，**<u>很多直播应用，都基于 UDP 实现了自己的视频传输协议</u>**。

 

#####  城会玩 三:实时游戏 

​	游戏有一个特点，就是实时性比较高。快一秒你干掉别人，慢一秒你被别人爆头，所以很多职业玩家会买非常专业的鼠标和键盘，争分夺秒。

​	**因而，实时游戏中客户端和服务端要建立长连接，来保证实时传输。但是游戏玩家很多，服务器却不多。由于维护 TCP 连接需要在内核维护一些数据结构，因而一台机器能够支撑的 TCP 连接数目是有限 的，然后 UDP 由于是没有连接的，在异步 IO 机制引入之前，常常是应对海量客户端连接的策略**。 

​	**另外还是 TCP 的强顺序问题，对战的游戏，对网络的要求很简单，玩家通过客户端发送给服务器鼠标和 键盘行走的位置，服务器会处理每个用户发送过来的所有场景，处理完再返回给客户端，客户端解析响应，渲染最新的场景展示给玩家**。 

​	如果出现一个数据包丢失，所有事情都需要停下来等待这个数据包重发。客户端会出现等待接收数据， 然而玩家并不关心过期的数据，激战中卡 1 秒，等能动了都已经死了。 

​	**游戏对实时要求较为严格的情况下，采用自定义的可靠 UDP 协议，自定义重传策略，能够把丢包产生的延迟降到最低，尽量减少网络问题对游戏性造成的影响。** 



#####  城会玩 四:IoT 物联网 

​	**一方面，物联网领域终端资源少，很可能只是个内存非常小的嵌入式系统，而维护 TCP 协议代价太大;** **另一方面，物联网对实时性要求也很高，而 TCP 还是因为上面的那些原因导致时延大**。Google 旗下的 Nest 建立Thread Group，**推出了物联网通信协议 Thread，就是基于 UDP 协议的**。 



#####  城会玩 五:移动通信领域 

​	在 4G 网络里，**移动流量上网的数据面对的协议 GTP-U 是基于 UDP 的**。因为移动网络协议比较复杂， 而 GTP 协议本身就包含复杂的手机上线下线的通信协议。如果基于 TCP，TCP 的机制就显得非常多余，这部分协议我会在后面的章节单独讲解。 

#### 6. 小结 

​	如果将 TCP 比作成熟的社会人，UDP 则是头脑简单的小朋友。TCP 复杂，UDP 简单;TCP 维护连 接，UDP 谁都相信;TCP 会坚持知进退;UDP 愣头青一个，勇往直前; 

​	UDP 虽然简单，但它有简单的用法。它可以用在环境简单、需要多播、应用层自己控制传输的地方。 例如 **DHCP、VXLAN、QUIC** 等。 



### 九、 **TCP协议(上):因性恶而复杂，先恶后善反轻松**

​	网络环境是恶劣的，丢包、乱序、重传，拥塞都是常有的事情，一言不合就可能送达不了，因而要从算法层面来保证可靠性。

#### 1.TCP 包头格式
​	我们先来看 TCP 头的格式。从这个图上可以看出，它比 UDP 复杂得多。

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp-1.png)

​	**首先，源端口号和目标端口号是不可少的**，这一点和 UDP 是一样的。如果没有这两个端口号。数据就不知道应该发给哪个应用。 

​	**接下来是包的序号。为什么要给包编号呢?当然是为了解决乱序的问题。**不编好号怎么确认哪个应该先来，哪个应该后到呢。编号是为了解决乱序问题。既然是社会老司机，做事当然要稳重，一件件来，面临再复杂的情况，也临危不乱。

​	**还应该有的就是确认序号**。发出去的包应该有确认，要不然我怎么知道对方有没有收到呢?如果没有收到就应该重新发送，直到送达。这个可以解决不丢包的问题。作为老司机，做事当然要靠谱，答应了就要做到，暂时做不到也要有个回复。

​	**TCP 是靠谱的协议，但是这不能说明它面临的网络环境好**。从 IP 层面来讲，如果网络状况的确那么差， 是没有任何可靠性保证的，而作为 IP 的上一层 TCP 也无能为力，唯一能做的就是更加努力，不断重传，通过各种算法保证。也就是说，对于 TCP 来讲，IP 层你丢不丢包，我管不着，但是我在我的层面上，会努力保证可靠性。 

​	这有点像如果你在北京，和客户约十点见面，那么你应该清楚堵车是常态，你干预不了，也控制不了，你唯一能做的就是早走。打车不行就改乘地铁，尽力不失约。

​	**接下来有一些状态位**。例如 **SYN 是发起一个连接**，**ACK 是回复**，**RST 是重新连接**，**FIN 是结束连接** 等。**<u>TCP 是面向连接的，因而双方要维护连接的状态，这些带状态位的包的发送，会引起双方的状态变更</u>**。 

​	不像小时候，随便一个不认识的小朋友都能玩在一起，人大了，就变得礼貌，优雅而警觉，人与人遇到
会互相热情的寒暄，离开会不舍的道别，但是人与人之间的信任会经过多次交互才能建立。

​	还有一个重要的就是**窗口大小**。**TCP 要做流量控制，通信双方各声明一个窗口，标识自己当前能够的处理能力**，别发送的太快，撑死我，也别发的太慢，饿死我。 

​	作为老司机，做事情要有分寸，待人要把握尺度，既能适当提出自己的要求，又不强人所难。**<u>除了做流量控制以外，TCP 还会做拥塞控制</u>**，对于真正的通路堵车不堵车，它无能为力，唯一能做的就是控制自己，也即控制发送的速度。不能改变世界，就改变自己嘛。
​	作为老司机，要会自我控制，知进退，知道什么时候应该坚持，什么时候应该让步。
​	**通过对 TCP 头的解析，我们知道要掌握 TCP 协议，重点应该关注以下几个问题**:

- **顺序问题** ，稳重不乱;
- **丢包问题**，承诺靠谱;
- **连接维护**，有始有终;
- **流量控制**，把握分寸;
- **拥塞控制**，知进知退。

#### 2. TCP 的三次握手

 	所有的问题，首先都要先建立一个连接，所以我们先来看连接维护问题。 

​	**TCP 的连接建立，我们常常称为三次握手**。 

A: 您好，我是 A。
B: 您好 A，我是 B。
A: 您好 B。

​	我们也常称为“**请求 -> 应答 -> 应答之应答**”的三个回合。这个看起来简单，其实里面还是有很多的学问，很多的细节。

​	**首先，为什么要三次，而不是两次?按说两个人打招呼，一来一回就可以了啊?为了可靠，为什么不是四次?**

​	我们还是假设这个通路是非常不可靠的，A 要发起一个连接，当发了第一个请求杳无音信的时候，会有很多的可能性，比如第一个请求包丢了，再如没有丢，但是绕了弯路，超时了，还有 B 没有响应，不想和我连接。 

​	A不能确认结果，于是再发，再发。终于，有一个请求包到了 B，但是请求包到了 B 的这个事情，目前 A 还是不知道的，A 还有可能再发。 

​	B 收到了请求包，就知道了 A 的存在，并且知道 A 要和它建立连接。如果 B 不乐意建立连接，则 A 会 重试一阵后放弃，连接建立失败，没有问题;如果 B 是乐意建立连接的，则会发送应答包给 A。 

​	**当然对于 B 来说，这个应答包也是一入网络深似海，不知道能不能到达 A。这个时候 B 自然不能认为连接是建立好了，因为应答包仍然会丢，会绕弯路，或者 A 已经挂了都有可能。** 

​	**而且这个时候 B 还能碰到一个诡异的现象就是，A 和 B 原来建立了连接，做了简单通信后，结束了连接。还记得吗?A 建立连接的时候，请求包重复发了几次，有的请求包绕了一大圈又回来了，B 会认为这也是一个正常的的请求的话，因此建立了连接，可以想象，这个连接不会进行下去，也没有个终结的时候，纯属单相思了。因而两次握手肯定不行。** 

​	**B 发送的应答可能会发送多次，但是只要一次到达 A，A 就认为连接已经建立了，因为对于 A 来讲，他的消息有去有回。A 会给 B 发送应答之应答，而 B 也在等这个消息，才能确认连接的建立，只有等到了这个消息，对于 B 来讲，才算它的消息有去有回**。 

​	当然 A 发给 B 的应答之应答也会丢，也会绕路，甚至 B 挂了。按理来说，还应该有个应答之应答之应答，这样下去就没底了。**所以四次握手是可以的，四十次都可以，关键四百次也不能保证就真的可靠了。只要双方的消息都有去有回，就基本可以了**。

​	**好在大部分情况下，A 和 B 建立了连接之后，A 会马上发送数据的，一旦 A 发送数据，则很多问题都得到了解决。例如 A 发给 B 的应答丢了，当 A 后续发送的数据到达的时候，B 可以认为这个连接已经建立，或者 B 压根就挂了，A 发送的数据，会报错，说 B 不可达，A 就知道 B 出事情了**。

​	当然你可以说 A 比较坏，就是不发数据，建立连接后空着。我们在程序设计的时候，可以要求开启 keepalive 机制，即使没有真实的数据包，也有探活包。 

​	另外，你作为服务端 B 的程序设计者，对于 A 这种长时间不发包的客户端，可以主动关闭，从而空出资 源来给其他客户端使用。 

​	**三次握手除了双方建立连接外，主要还是为了沟通一件事情，就是<u>TCP 包的序号</u>的问题。**

​	**A 要告诉 B，我这面发起的包的序号起始是从哪个号开始的，B 同样也要告诉 A，B 发起的包的序号起始是从哪个号开始的。为什么序号不能都从 1 开始呢?因为这样往往会出现冲突**。 

​	例如，A 连上 B 之后，发送了 1、2、3 三个包，但是发送 3 的时候，中间丢了，或者绕路了，于是重新 发送，后来 A 掉线了，重新连上 B 后，序号又从 1 开始，然后发送 2，但是压根没想发送 3，但是上次绕路的那个 3 又回来了，发给了 B，B 自然认为，这就是下一个包，于是发生了错误。 

​	因而，**每个连接都要有不同的序号。这个序号的起始序号是随着时间变化的，可以看成一个 32 位的计数器，每 4ms 加一，**如果计算一下，如果到重复，需要 4 个多小时，那个绕路的包早就死翘翘了，因为我们都知道 IP 包头里面有个 TTL，也即生存时间。 

​	好了，**双方终于建立了信任，建立了连接**。前面也说过，**为了维护这个连接，双方都要维护一个状态机，在连接建立的过程中，双方的状态变化时序图就像这样**。

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp-2.png)

​	**一开始，客户端和服务端都处于 CLOSED 状态**。**先是服务端主动监听某个端口，处于 LISTEN 状态**。然后**客户端主动发起连接 SYN**，**之后处于 SYN-SENT 状态**。**服务端收到发起的连接，返回 SYN，并且ACK 客户端的 SYN，之后处于 SYN-RCVD 状态**。**客户端收到服务端发送的 SYN 和 ACK 之后，发送ACK 的 ACK，之后处于 ESTABLISHED 状态，因为它一发一收成功了。服务端收到 ACK 的 ACK 之后，处于 ESTABLISHED 状态，因为它也一发一收了**。

#### 3. TCP 四次挥手

​	好了，说完了连接，接下来说一说“拜拜”，好说好散。这常被称为四次挥手。 

A: B 啊，我不想玩了。 

B: 哦，你不想玩了啊，我知道了。 

​	**这个时候，还只是 A 不想玩了，也即 A 不会再发送数据，但是 B 能不能在 ACK 的时候，直接关闭呢? 当然不可以了，很有可能 A 是发完了最后的数据就准备不玩了，但是 B 还没做完自己的事情，还是可以发送数据的**，所以称为**<u>半关闭的状态</u>**。 

​	这个时候 **A 可以选择不再接收数据了，也可以选择最后再接收一段数据，等待 B 也主动关闭**。 

 B:A 啊，好吧，我也不玩了，拜拜。
 A:好的，拜拜。 

​	**这样整个连接就关闭了。但是这个过程有没有异常情况呢?**当然有，上面是和平分手的场面。 

​	A 开始说“不玩了”，B 说“知道了”，这个回合，是没什么问题的，因为在此之前，双方还处于合作的状态，如果A 说“不玩了”，没有收到回复，则 A 会重新发送“不玩了”。但是这个回合结束之后， 就有可能出现异常情况了，因为已经有一方率先撕破脸。 

​	一种情况是，A 说完“不玩了”之后，直接跑路，是会有问题的，因为 B 还没有发起结束，而如果 A 跑路，B 就算发起结束，也得不到回答，B 就不知道该怎么办了。另一种情况是，A 说完“不玩了”，B 直接跑路，也是有问题的，因为 A 不知道 B 是还有事情要处理，还是过一会儿会发送结束。 

​	那怎么解决这些问题呢?TCP 协议专门设计了几个状态来处理这些问题。我们来看断开连接的时候的状态时序图。 

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp-3.png)

​	断开的时候，我们可以看到，当 A 说“不玩了”，就进入 FIN_WAIT_1 的状态，B 收到“A 不玩”的消 息后，发送知道了，就进入 CLOSE_WAIT 的状态。 

​	A 收到“B 说知道了”，就进入 FIN_WAIT_2 的状态，如果这个时候 B 直接跑路，则 A 将永远在这个状 态。TCP 协议里面并没有对这个状态的处理，但是 Linux 有，可以调整 tcp_fin_timeout 这个参数，设 置一个超时时间。 

​	如果 B 没有跑路，发送了“B 也不玩了”的请求到达 A 时，A 发送“知道 B 也不玩了”的 ACK 后，从 FIN_WAIT_2 状态结束，按说 A 可以跑路了，但是最后的这个 ACK 万一 B 收不到呢?则 B 会重新发一 个“B 不玩了”，这个时候 A已经跑路了的话，B 就再也收不到 ACK 了，因而 TCP 协议要求 A 最后等 待一段时间 TIME_WAIT，这个时间要足够长，长到如果 B 没收到 ACK 的话，“B 说不玩了”会重发 的，A 会重新发一个 ACK 并且足够时间到达 B。 

​	A 直接跑路还有一个问题是，A 的端口就直接空出来了，但是 B 不知道，B 原来发过的很多包很可能还 在路上，如果 A 的端口被一个新的应用占用了，这个新的应用会收到上个连接中 B 发过来的包，虽然序 列号是重新生成的，但是这里要上一个双保险，防止产生混乱，因而也需要等足够长的时间，等到原来 B 发送的所有的包都死翘翘，再空出端口来。 

​	等待的时间设为 2MSL，MSL是Maximum Segment Lifetime，报文最大生存时间，它是任何报文在网 络上存在的最长时间，超过这个时间报文将被丢弃。因为 TCP 报文基于是 IP 协议的，而 IP 头中有一个 TTL 域，是 IP 数据报可以经过的最大路由数，每经过一个处理他的路由器此值就减 1，当此值为 0 则数 据报将被丢弃，同时发送 ICMP 报文通知源主机。协议规定 MSL 为 2 分钟，实际应用中常用的是 30 秒，1 分钟和 2 分钟等。 

​	还有一个异常情况就是，B 超过了 2MSL 的时间，依然没有收到它发的 FIN 的 ACK，怎么办呢? 按照TCP 的原理，B 当然还会重发 FIN，这个时候 A 再收到这个包之后，A 就表示，我已经在这里等了这么长时间了，已经仁至义尽了，之后的我就都不认了，于是就直接发送 RST，B 就知道 A 早就跑了。

#### 3. TCP 状态机

将连接建立和连接断开的两个时序状态图综合起来，就是这个著名的 TCP 的状态机。学习的时候比较建议将这个状态机和时序状态机对照着看，不然容易晕。 

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp-4.png)

在这个图中，加黑加粗的部分，是上面说到的主要流程，其中阿拉伯数字的序号，是连接过程中的顺序，而大写中文数字的序号，是连接断开过程中的顺序。加粗的实线是客户端 A 的状态变迁，加粗的虚线是服务端 B 的状态变迁。



### 十、TCP策略算法

​	我们前面说到玄奘西行，要出网关。既然出了网关，那就是在公网上传输数据，公网往往是不可靠的，因而需要很多的机制去保证传输的可靠性，这里面需要恒心，也即各种重传的策略，还需要有智慧，也就是说，**这里面包含着大量的算法**。

#### 1. 如何做个靠谱的人?

​		TCP 想成为一个成熟稳重的人，成为一个靠谱的人。那一个人怎么样才算靠谱呢?咱们工作中经常就有 这样的场景，比如你交代给下属一个事情以后，下属到底能不能做到，做到什么程度，什么时候能够交 付，往往就会有应答，有回复。这样，处理事情的过程中，一旦有异常，你也可以尽快知道，而不是交 代完之后就石沉大海，过了一个月再问，他说，啊我不记得了。 

​		对应到网络协议上，就是客户端每发送的一个包，服务器端都应该有个回复，如果服务器端超过一定的时间没有回复，客户端就会重新发送这个包，直到有回复。

​		这个发送应答的过程是什么样呢?可以是上一个收到了应答，再发送下一个。这种模式有点像两个人直接打电话，你一句，我一句。但是这种方式的缺点是效率比较低。如果一方在电话那头处理的时间比较长，这一头就要干等着，双方都没办法干其他事情。咱们在日常工作中也不是这样的，不能你交代你的下属办一件事情，就一直打着电话看着他做，而是应该他按照你的安排，先将事情记录下来，办完一件回复一件。在他办事情的过程中，你还可以同时交代新的事情，这样双方就并行了。

​		如果使用这种模式，其实需要你和你的下属就不能靠脑子了，而是要都准备一个本子，你每交代下属一个事情，双方的本子都要记录一下。
​		当你的下属做完一件事情，就回复你，做完了，你就在你的本子上将这个事情划去。同时你的本子上每件事情都有时限，如果超过了时限下属还没有回复，你就要主动重新交代一下:上次那件事情，你还没回复我，咋样啦?

​	既然多件事情可以一起处理，那就需要给每个事情编个号，防止弄错了。例如，程序员平时看任务的时候，都会看 JIRA 的 ID，而不是每次都要描述一下具体的事情。在大部分情况下，对于事情的处理是按 照顺序来的，先来的先处理，这就给应答和汇报工作带来了方便。等开周会的时候，每个程序员都可以 将 JIRA ID 的列表拉出来，说以上的都做完了，而不用一个个说。 



#### 2. 如何实现一个靠谱的协议?

​		TCP 协议使用的也是同样的模式。为了保证顺序性，每一个包都有一个 ID。在建立连接的时候，会商定起始的 ID 是什么，然后按照 ID 一个个发送。为了保证不丢包，对于发送的包都要进行应答，但是这个应答也不是一个一个来的，而是**会应答某个之前的 ID，表示都收到了，这种模式称为累计确认或者累计应答**(cumulative acknowledgment)。 

​		**为了记录所有发送的包和接收的包，TCP 也需要发送端和接收端分别都有缓存来保存这些记录**。发送端的缓存里是按照包的 ID 一个个排列，根据处理的情况分成四个部分。 

​		**第一部分**:发送了并且已经确认的。这部分就是你交代下属的，并且也做完了的，应该划掉的。
​		**第二部分**:发送了并且尚未确认的。这部分是你交代下属的，但是还没做完的，需要等待做完的回复之后，才能划掉。
​		**第三部分**:没有发送，但是已经等待发送的。这部分是你还没有交代给下属，但是马上就要交代的。
​		**第四部分**:没有发送，并且暂时还不会发送的。这部分是你还没有交代给下属，而且暂时还不会交代给下属的。
​		**这里面为什么要区分第三部分和第四部分呢?没交代的，一下子全交代了不就完了吗?**
​		这就是我们上一节提到的十个词口诀里的“流量控制，把握分寸”。**作为项目管理人员，你应该根据以往的工作情况和这个员工反馈的能力、抗压力等，先在心中估测一下，这个人一天能做多少工作。**如果工作布置少了，就会不饱和;如果工作布置多了，他就会做不完;如果你使劲逼迫，人家可能就要辞职了。

​		**到底一个员工能够同时处理多少事情呢?**在 TCP 里，**接收端会给发送端报一个窗口的大小**，叫 `Advertised window`。**这个窗口的大小应该等于上面的第二部分加上第三部分，就是已经交代了没做完 的加上马上要交代的**。超过这个窗口的，接收端做不过来，就不能发送了。 

​		于是，**发送端需要保持下面的数据结构**。

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp-5.png)

- **LastByteAcked**:第一部分和第二部分的分界线
- **LastByteSent**:第二部分和第三部分的分界线
- **LastByteAcked** + **AdvertisedWindow**:第三部分和第四部分的分界线

​      

​		 **对于接收端来讲，它的缓存里记录的内容要简单一些。**

**第一部分**:接受并且确认过的。也就是我领导交代给我，并且我做完的。
**第二部分**:还没接收，但是马上就能接收的。也即是我自己的能够接受的最大工作量。
**第三部分**:还没接收，也没法接收的。也即超过工作量的部分，实在做不完。

​		对应的数据结构就像这样。

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp-6.png)

- **MaxRcvBuffer**:最大缓存的量;
- **LastByteRead**之后是已经接收了，但是还没被应用层读取的; 
- **NextByteExpected** 是第一部分和第二部分的分界线。

**第二部分的窗口有多大呢?**

`NextByteExpected `和` LastByteRead` 的差其实是还没被应用层读取的部分占用掉的 `MaxRcvBuffer` 的量，我们定义为 A。 

`AdvertisedWindow `其实是` MaxRcvBuffer` 减去 A。 也就是:`AdvertisedWindow=MaxRcvBuffer-((NextByteExpected-1)-LastByteRead)`。 

​		**那第二部分和第三部分的分界线在哪里呢?**NextByteExpected 加 AdvertisedWindow 就是第二部分和 第三部分的分界线，其实也就是 LastByteRead 加上 MaxRcvBuffer。 

​	:star:	**其中第二部分里面，由于受到的包可能不是顺序的，会出现空挡，只有和第一部分连续的，可以马上进行回复，中间空着的部分需要等待，哪怕后面的已经来了**。

#### 3.**顺序问题与丢包问题** 

​		接下来我们结合一个例子来看。

​		还是刚才的图，在发送端来看，1、2、3 已经发送并确认;4、5、6、7、8、9 都是发送了还没确认; 10、11、12 是还没发出的;13、14、15 是接收方没有空间，不准备发的。 

​		在接收端来看，1、2、3、4、5 是已经完成 ACK，但是没读取的;**6、7 是等待接收的;**8、9 是已经接收，但是没有 ACK 的。 

**发送端和接收端当前的状态如下:**

1、2、3 没有问题，双方达成了一致。 

4、5 接收方说 ACK 了，但是发送方还没收到，有可能丢了，有可能在路上。 

**6、7、8、9 肯定都发了，但是 8、9 已经到了，但是 6、7 没到，出现了乱序，缓存着但是没办法 ACK**。 



​		根据这个例子，我们可以知道，顺序问题和丢包问题都有可能发生，所以我们先来看确认与重发的机制。

​		**假设 4 的确认到了，不幸的是，5 的 ACK 丢了，6、7 的数据包丢了，这该怎么办呢?** 

​		一种方法就是**超时重试，**也即对每一个发送了，但是没有 ACK 的包，都有设一个定时器，超过了一定的时间，就重新尝试。但是这个超时的时间如何评估呢?**这个时间不宜过短，时间必须大于往返时间 RTT，否则会引起不必要的重传**。**也不宜过长，这样超时时间变长，访问就变慢了**。 

​		**估计往返时间，需要 TCP 通过采样 RTT 的时间，然后进行加权平均，算出一个值，而且这个值还是要 不断变化的，因为网络状况不断的变化。除了采样 RTT，还要采样 RTT 的波动范围，计算出一个估计的超时时间。**由于**重传时间是不断变化**的，我们称为**自适应重传算法(Adaptive Retransmission Algorithm)**。 

​		如果过一段时间，5、6、7 都超时了，就会重新发送。接收方发现 5 原来接收过，于是丢弃 5;6 收到了，发送 ACK，要求下一个是 7，7 不幸又丢了。当 7 再次超时的时候，**有需要重传的时候，TCP 的策略是超时间隔加倍**。每当遇到一次超时重传的时候，都会将下一次超时时间间隔设为先前值的两倍。**两次超时，就说明网络环境差，不宜频繁反复发送**。 

​		**超时触发重传存在的问题是，超时周期可能相对较长**。那是不是可以有更快的方式呢?

​		有一个可以**快速重传的机制，当接收方收到一个序号大于下一个所期望的报文段时，就检测到了数据流中的一个间格，于是发送三个冗余的 ACK，客户端收到后，就在定时器过期之前，重传丢失的报文段**。 

​		例如，接收方发现 6、8、9 都已经接收了，就是 7 没来，那肯定是丢了，于是发送三个 6 的 ACK，要 求下一个是 7。客户端收到 3 个，就会发现 7 的确又丢了，不等超时，马上重发。 

​		还有一种方式称为**Selective Acknowledgment (SACK)**。这种方式需要在 TCP 头里加一个 SACK 的 东西，可以将缓存的地图发送给发送方。例如可以发送 ACK6、SACK8、SACK9，有了地图，发送方一 下子就能看出来是 7 丢了。



#### 4.流量控制问题

​		**在对于包的确认中，同时会携带一个窗口的大小。**

​		我们先假设窗口不变的情况，窗口始终为 9。4 的确认来的时候，会右移一个，这个时候第 13 个包也可 以发送了。 

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp2-1.png)

​		这个时候，假设发送端发送过猛，会将第三部分的 10、11、12、13 全部发送完毕，之后就停止发送了，未发送可发送部分为 0。

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp2-2.png)

​		当对于包 5 的确认到达的时候，在客户端相当于窗口再滑动了一格，这个时候，才可以有更多的包可以发送了，例如第 14 个包才可以发送。

​		如果接收方实在处理的太慢，导致缓存中没有空间了，可以通过确认信息修改窗口的大小，甚至可以设置为 0，则发送方将暂时停止发送。

​		我们假设一个极端情况，接收端的应用一直不读取缓存中的数据，当数据包 6 确认后，窗口大小就不能再是 9 了，就要缩小一个变为 8。

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp2-3.png)

这个新的窗口 8 通过 6 的确认消息到达发送端的时候，你会发现窗口没有平行右移，而是仅仅左面的边右移了，窗口的大小从 9 改成了 8。

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp2-4.png)

如果接收端还是一直不处理数据，则随着确认的包越来越多，窗口越来越小，直到为 0。

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp2-6.png)

​		当这个窗口通过包 14 的确认到达发送端的时候，发送端的窗口也调整为 0，停止发送。

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp2-7.png)

​		如果这样的话，发送方会定时发送窗口探测数据包，看是否有机会调整窗口的大小。当接收方比较慢的时候，要防止低能窗口综合征，别空出一个字节来就赶快告诉发送方，然后马上又填满了，可以当窗口太小的时候，不更新窗口，直到达到一定大小，或者缓冲区一半为空，才更新窗口。这就是我们常说的流量控制。

#### 5.拥塞控制问题 

​		最后，我们看一下拥塞控制的问题，也是通过窗口的大小来控制的，**前面的滑动窗口 rwnd 是怕发送方 把接收方缓存塞满，而拥塞窗口 cwnd，是怕把网络塞满**。 

​		这里有一个公式 **LastByteSent - LastByteAcked <= min {cwnd, rwnd}** ，是拥塞窗口和滑动窗口共同 控制发送的速度。 

​		那发送方怎么判断网络是不是满呢?这其实是个挺难的事情，因为对于 TCP 协议来讲，他压根不知道整个网络路径都会经历什么，对他来讲就是一个黑盒。TCP 发送包常被比喻为往一个水管里面灌水，而 TCP 的拥塞控制就是在不堵塞，不丢包的情况下，尽量发挥带宽。 

​		水管有粗细，网络有带宽，也即每秒钟能够发送多少数据;水管有长度，端到端有时延。在理想状态 下，水管里面水的量 = 水管粗细 x 水管长度。对于到网络上，通道的容量 = 带宽 × 往返延迟。 

​	如果我们设置发送窗口，使得发送但未确认的包为为通道的容量，就能够撑满整个管道。	 

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp2-8.png)



​		如图所示，假设往返时间为 8s，去 4s，回 4s，每秒发送一个包，每个包 1024byte。已经过去了 8s， 则 8 个包都发出去了，其中前 4 个包已经到达接收端，但是 ACK 还没有返回，不能算发送成功。5-8 后四个包还在路上，还没被接收。这个时候，整个管道正好撑满，在发送端，已发送未确认的为 8 个 包，正好等于带宽，也即每秒发送 1 个包，乘以来回时间 8s。 

​		**如果我们在这个基础上再调大窗口，使得单位时间内更多的包可以发送，会出现什么现象呢?**

​		我们来想，原来发送一个包，从一端到达另一端，假设一共经过四个设备，每个设备处理一个包时间耗费 1s，所以到达另一端需要耗费 4s，如果发送的更加快速，则单位时间内，会有更多的包到达这些中间 设备，这些设备还是只能每秒处理一个包的话，多出来的包就会被丢弃，这是我们不想看到的。 

​		这个时候，我们可以想其他的办法，例如这个四个设备本来每秒处理一个包，但是我们在这些设备上加缓存，处理不过来的在队列里面排着，这样包就不会丢失，但是缺点是会增加时延，这个缓存的包，4s 肯定到达不了接收端了，如果时延达到一定程度，就会超时重传，也是我们不想看到的。 

​		**于是 TCP 的拥塞控制主要来避免两种现象，包丢失和超时重传**。一旦出现了这些现象就说明，发送速度 太快了，要慢一点。但是一开始我怎么知道速度多快呢，我怎么知道应该把窗口调整到多大呢? 

​		如果我们通过漏斗往瓶子里灌水，我们就知道，不能一桶水一下子倒进去，肯定会溅出来，要一开始慢慢的倒，然后发现总能够倒进去，就可以越倒越快。这叫作**慢启动**。

​		一条 TCP 连接开始，cwnd 设置为一个报文段，一次只能发送一个;当收到这一个确认的时候，cwnd加一，于是一次能够发送两个;当这两个的确认到来的时候，每个确认 cwnd 加一，两个确认 cwnd 加二，于是一次能够发送四个;当这四个的确认到来的时候，每个确认 cwnd 加一，四个确认 cwnd 加四，于是一次能够发送八个。可以看出这是指数性的增长。

​		涨到什么时候是个头呢?有一个值 ssthresh 为 65535 个字节，当超过这个值的时候，就要小心一点了，不能倒这么快了，可能快满了，再慢下来。

​		每收到一个确认后，cwnd 增加 1/cwnd，我们接着上面的过程来，一次发送八个，当八个确认到来的时 候，每个确认增加 1/8，八个确认一共 cwnd 增加 1，于是一次能够发送九个，变成了线性增长。 

​		但是线性增长还是增长，还是越来越多，直到有一天，水满则溢，出现了拥塞，这时候一般就会一下子降低倒水的速度，等待溢出的水慢慢渗下去。

​		拥塞的一种表现形式是丢包，需要超时重传，这个时候，将 sshresh 设为 cwnd/2，将 cwnd 设为 1， 重新开始慢启动。这真是一旦超时重传，马上回到解放前。但是这种方式太激进了，将一个高速的传输 速度一下子停了下来，会造成网络卡顿。 

​		前面我们讲过快速重传算法。当接收端发现丢了一个中间包的时候，发送三次前一个包的 ACK，于是发送端就会快速的重传，不必等待超时再重传。TCP 认为这种情况不严重，因为大部分没丢，只丢了一小 部分，cwnd 减半为 cwnd/2，然后 sshthresh = cwnd，当三个包返回的时候，cwnd = sshthresh + 3，也就是没有一夜回到解放前，而是还在比较高的值，呈线性增长。 

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp2-10.png)



​		就像前面说的一样，正是这种知进退，使得时延很重要的情况下，反而降低了速度。但是如果你仔细想一下，TCP 的拥塞控制主要来避免的两个现象都是有问题的。

第一个问题是**丢包并不代表着通道满了，也可能是管子本来就漏水**。例如公网上带宽不满也会丢包，这个时候就认为拥塞了，退缩了，其实是不对的。

第二个问题是 **TCP 的拥塞控制要等到将中间设备都填充满了，才发生丢包，从而降低速度，这时候已经晚了**。其实 TCP 只要填满管道就可以了，不应该接着填，直到连缓存也填满。

​		 为了优化这两个问题，后来有了**TCP BBR 拥塞算法**。它企图找到一个平衡点，就是通过不断的加快发送速度，将管道填满，但是不要填满中间设备的缓存，因为这样时延会增加，在这个平衡点可以很好的达到高带宽和低时延的平衡。

![](/Users/nali/songyintao/SongYintao.github.io/img/tcp2-9.png)

### 十一、套接字Socket

​		在讲 TCP 和 UDP 协议的时候，我们分客户端和服务端，在写程序的时候，我们也同样这样分。 

​		Socket 这个名字很有意思，可以作插口或者插槽讲。虽然我们是写软件程序，但是你可以想象为弄一根网线，一头插在客户端，一头插在服务端，然后进行通信。所以在通信之前，双方都要建立一个 Socket。 

​		在建立 Socket 的时候，应该设置什么参数呢?Socket 编程进行的是端到端的通信，往往意识不到中间经过多少局域网，多少路由器，因而能够设置的参数，也只能是端到端协议之上网络层和传输层的。 

​		在网络层，Socket 函数需要指定到底是 IPv4 还是 IPv6，分别对应设置为 AF_INET 和 AF_INET6。另外，还要指定到底是 TCP 还是 UDP。还记得咱们前面讲过的，**TCP 协议是基于数据流的**，所以设置为 SOCK_STREAM，而 **UDP 是基于数据报**的，因而设置为 SOCK_DGRAM。 

#### 1.基于 TCP 协议的 Socket 程序函数调用过程
​		两端创建了 Socket 之后，接下来的过程中，TCP 和 UDP 稍有不同，我们先来看 TCP。

​		**TCP 的服务端要先监听一个端口，一般是先调用 bind 函数，给这个 Socket 赋予一个 IP 地址和端口**。为什么需要端口呢?要知道，你写的是一个应用程序，当一个网络包来的时候，内核要通过 TCP 头里面的这个端口，来找到你这个应用程序，把包给你。为什么要 IP 地址呢?有时候，一台机器会有多个网卡，也就会有多个 IP 地址，你可以选择监听所有的网卡，也可以选择监听一个网卡，这样，只有发给这个网卡的包，才会给你。

​		**当服务端有了 IP 和端口号，就可以调用 listen 函数进行监听**。在 TCP 的状态图里面，有一个 listen 状 态，当调用这个函数之后，服务端就进入了这个状态，这个时候客户端就可以发起连接了。 

​		**在内核中，为每个 Socket 维护两个队列。一个是已经建立了连接的队列，这时候连接三次握手已经完 毕，处于 established 状态;一个是还没有完全建立连接的队列，这个时候三次握手还没完成，处于 syn_rcvd 的状态**。 

​		接下来，服务端调用 accept 函数，拿出一个已经完成的连接进行处理。如果还没有完成，就要等着。 

​		**在服务端等待的时候，客户端可以通过 connect 函数发起连接。先在参数中指明要连接的 IP 地址和端口号，然后开始发起三次握手。内核会给客户端分配一个临时的端口。一旦握手成功，服务端的 accept 就会返回另一个 Socket**。 

​		这是一个经常考的知识点，就是**监听的 Socket 和真正用来传数据的 Socket 是两个**，一个叫作监听 Socket，一个叫作已连接 Socket。 

​		**连接建立成功之后，双方开始通过 read 和 write 函数来读写数据**，就像往一个文件流里面写东西一样。 这个图就是基于 TCP 协议的 Socket 程序函数调用过程。 

![](/Users/nali/songyintao/SongYintao.github.io/img/socket-1.png)

​		说 TCP 的 Socket 就是一个文件流，是非常准确的。因为，**Socket 在 Linux 中就是以文件的形式存在的**。除此之外，**还存在文件描述符**。**写入和读出，也是通过文件描述符**。

​		**在内核中，Socket 是一个文件，那对应就有文件描述符**。每一个进程都有一个**数据结构 task_struct，里面指向一个文件描述符数组，来列出这个进程打开的所有文件的文件描述符**。文件描述符是一个整数，是这个数组的下标。

​		这个**数组中的内容是一个指针**，**指向内核中所有打开的文件的列表**。**既然是一个文件，就会有一个inode，只不过 Socket 对应的 inode 不像真正的文件系统一样，保存在硬盘上的，而是在内存中的**。在这个 inode 中，**指向了 Socket 在内核中的 Socket 结构**。

​		**在这个结构里面，主要的是两个队列，一个是发送队列，一个是接收队列**。在这两个队列里面保存的是一个缓存 **sk_buff**。**这个缓存里面能够看到完整的包的结构**。看到这个，是不是能和前面讲过的收发包的场景联系起来了?

![](/Users/nali/songyintao/SongYintao.github.io/img/socket-2.png)

#### 2. 基于 UDP 协议的 Socket 程序函数调用过程

​		对于 UDP 来讲，过程有些不一样。**UDP 是没有连接的，所以不需要三次握手，也就不需要调用 listen和 connect，但是，UDP 的的交互仍然需要 IP 和端口号，因而也需要 bind。UDP 是没有维护连接状态的，因而不需要每对连接建立一组 Socket，而是只要有一个 Socket，就能够和多个客户端通信**。也正是因为没有连接状态，每次通信的时候，都调用 sendto 和 recvfrom，都可以传入 IP 地址和端口。 

​		这个图的内容就是基于 UDP 协议的 Socket 程序函数调用过程。 

![](/Users/nali/songyintao/SongYintao.github.io/img/scoket-3.png)



#### 3.服务器如何接更多的项目?

​		会了这几个基本的 Socket 函数之后，你就可以轻松地写一个网络交互的程序了。就像上面的过程一样， 在建立连接后，进行一个 while 循环。客户端发了收，服务端收了发。 

​		当然这只是万里长征的第一步，因为如果使用这种方法，基本上只能一对一沟通。如果你是一个服务器，同时只能服务一个客户，肯定是不行的。这就相当于老板成立一个公司，只有自己一个人，自己亲自上来服务客户，只能干完了一家再干下一家，这样赚不来多少钱。那作为老板你就要想了，我最多能接多少项目呢?当然是越多越好。

我们先来算一下理论值，也就是最大连接数，系统会用一个四元组来标识一个 TCP 连接。

**{本机 IP, 本机端口, 对端 IP, 对端端口}**

​		**服务器通常固定在某个本地端口上监听，等待客户端的连接请求**。因此，**服务端端 TCP 连接四元组中只有对端 IP, 也就是客户端的 IP 和对端的端口，也即客户端的端口是可变的**，因此，最大 TCP 连接数 = **客户端 IP 数×客户端端口数**。对 IPV4，客户端的 IP 数最多为 2 的 32 次方，客户端的端口数最多为 2 的 16 次方，也就是服务端单机最大 TCP 连接数，约为 2 的 48 次方。 

​		当然，**服务端最大并发 TCP 连接数远不能达到理论上限。首先主要是文件描述符限制，按照上面的原理，Socket 都是文件，所以首先要通过 ulimit 配置文件描述符的数目**;**另一个限制是内存，按上面的数 据结构，每个 TCP 连接都要占用一定内存，操作系统是有限的**。 

​		所以，作为老板，**在资源有限的情况下，要想接更多的项目，就需要降低每个项目消耗的资源数目**。



##### 方式一:将项目外包给其他公司(多进程方式)

​		这就相当于你是一个代理，在那里监听来的请求。一旦建立了一个连接，就会有一个已连接 Socket，这时候你可以创建一个子进程，然后将基于已连接 Socket 的交互交给这个新的子进程来做。就像来了一个新的项目，但是项目不一定是你自己做，可以再注册一家子公司，招点人，然后把项目转包给这家子公 司做，以后对接就交给这家子公司了，你又可以去接新的项目了。 

​		**这里有一个问题是，如何创建子公司，并如何将项目移交给子公司呢?**

​		**在 Linux 下，创建子进程使用 fork 函数**。通过名字可以看出，这是在父进程的基础上完全拷贝一个子进程。在 Linux 内核中，**会复制文件描述符的列表，也会复制内存空间，还会复制一条记录当前执行到了 哪一行程序的进程**。显然，**复制的时候在调用 fork，复制完毕之后，父进程和子进程都会记录当前刚刚 执行完 fork**。这两个进程刚复制完的时候，几乎一模一样，只是根据 fork 的返回值来区分到底是父进程，还是子进程。如果返回值是 0，则是子进程;如果返回值是其他的整数，就是父进程。 

​		**进程复制过程我画在这里。**

![](/Users/nali/songyintao/SongYintao.github.io/img/socket-4.png)

​		**因为复制了文件描述符列表，而文件描述符都是指向整个内核统一的打开文件列表的，因而父进程刚才因为 accept 创建的已连接 Socket 也是一个文件描述符，同样也会被子进程获得**。

​		**接下来，子进程就可以通过这个已连接 Socket 和客户端进行互通了，当通信完毕之后，就可以退出进程，那父进程如何知道子进程干完了项目，要退出呢?还记得 fork 返回的时候，如果是整数就是父进程吗?这个整数就是子进程的 ID，父进程可以通过这个 ID 查看子进程是否完成项目，是否需要退出**。 



##### 方式二:将项目转包给独立的项目组(多线程方式)
​		上面这种方式你应该也能发现问题，如果每次接一个项目，都申请一个新公司，然后干完了，就注销掉这个公司，实在是太麻烦了。毕竟一个新公司要有新公司的资产，有新的办公家具，每次都买了再卖，不划算。

​		于是你应该想到了，**我们可以使用线程。相比于进程来讲，这样要轻量级的多。如果创建进程相当于成立新公司，购买新办公家具，而创建线程，就相当于在同一个公司成立项目组**。一个项目做完了，那这个项目组就可以解散，组成另外的项目组，办公家具可以共用。

​		在 Linux 下，**通过 pthread_create 创建一个线程，也是调用 do_fork。不同的是，虽然新的线程在 task 列表会新创建一项，但是很多资源，例如文件描述符列表、进程空间，还是共享的，只不过多了一 个引用而已**。 

![](/Users/nali/songyintao/SongYintao.github.io/img/socket-5.png)

​		新的线程也可以通过已连接 Socket 处理请求，从而达到并发处理的目的。 

​		上面基于进程或者线程模型的，其实还是有问题的。新到来一个 TCP 连接，就需要分配一个进程或者线程。一台机器无法创建很多进程或者线程。有个C10K，它的意思是一台机器要维护 1 万个连接，就要创 建 1 万个进程或者线程，那么操作系统是无法承受的。如果维持 1 亿用户在线需要 10 万台服务器，成本也太高了。 

​		**其实 C10K 问题就是，你接项目接的太多了，如果每个项目都成立单独的项目组，就要招聘 10 万人， 你肯定养不起，那怎么办呢?** 



#####方式三:一个项目组支撑多个项目(IO 多路复用，一个线程维护多个 Socket) 

​		当然，一个项目组可以看多个项目了。这个时候，每个项目组都应该有个项目进度墙，将自己组看的项目列在那里，然后每天通过项目墙看每个项目的进度，一旦某个项目有了进展，就派人去盯一下。

​		**由于 Socket 是文件描述符，因而某个线程盯的所有的 Socket，都放在一个文件描述符集合 fd_set 中， 这就是项目进度墙，然后调用 select 函数来监听文件描述符集合是否有变化**。**一旦有变化，就会依次查看每个文件描述符。那些发生变化的文件描述符在 fd_set 对应的位都设为 1，表示 Socket 可读或者可写，从而可以进行读写操作，然后再调用 select，接着盯着下一轮的变化**。

#####方式四:一个项目组支撑多个项目(IO 多路复用，从“派人盯着”到“有事通知”) 

​		**上面 select 函数还是有问题的**，因为每次 Socket 所在的文件描述符集合中有 Socket 发生变化的时 候，都需要通过轮询的方式，也就是需要将全部项目都过一遍的方式来查看进度，这大大影响了一个项 目组能够支撑的最大的项目数量。**因而使用 select，能够同时盯的项目数量由 FD_SETSIZE 限制**。 

​		**如果改成事件通知的方式，情况就会好很多，项目组不需要通过轮询挨个盯着这些项目，而是当项目进度发生变化的时候，主动通知项目组，然后项目组再根据项目进展情况做相应的操作。**

​		**能完成这件事情的函数叫 epoll，它在内核中的实现不是通过轮询的方式，而是通过注册 callback 函数 的方式，当某个文件描述符发送变化的时候，就会主动通知**。 

![](/Users/nali/songyintao/SongYintao.github.io/img/socket-6.png)

​		如图所示，**假设进程打开了 Socket m, n, x 等多个文件描述符，现在需要通过 epoll 来监听是否这些 Socket 都有事件发生。**其中 `epoll_create` 创建一个 **epoll 对象，也是一个文件，也对应一个文件描述 符，同样也对应着打开文件列表中的一项。**在这项里面有一个红黑树，**在红黑树里，要保存这个 epoll 要监听的所有 Socket**。 

​		**当 epoll_ctl 添加一个 Socket 的时候，其实是加入这个红黑树，同时红黑树里面的节点指向一个结构， 将这个结构挂在被监听的 Socket 的事件列表中**。**当一个 Socket 来了一个事件的时候，可以从这个列表 中得到 epoll 对象，并调用 call back 通知它。** 

​		这种通知方式使得监听的 Socket 数据增加的时候，效率不会大幅度降低，能够同时监听的 Socket 的数目也非常的多了。上限就为系统定义的、进程打开的最大文件描述符个数。因而，epoll 被称为解决 C10K 问题的利器。 





### 十二、HTTP协议

​		HTTP 协议，几乎是每个人上网用的第一个协议，同时也是很容易被人忽略的协议。 既然说看新闻，咱们就先登录 http://www.163.com 。 

​		http://www.163.com 是个 URL，叫作**统一资源定位符**。之所以叫统一，是因为它是有格式的。HTTP 称为协议，www.163.com 是一个域名，表示互联网上的一个位置。有的 URL 会有更详细的位置标识， 例如 http://www.163.com/index.html 。正是因为这个东西是统一的，所以当你把这样一个字符串输 入到浏览器的框里的时候，浏览器才知道如何进行统一处理。 

#### 1.HTTP 请求的准备 

​		浏览器会将 www.163.com 这个**域名发送给 DNS 服务器，让它解析为 IP 地址**。有关 DNS 的过程，其实非常复杂，这个在后面专门介绍 DNS 的时候，我会详细描述，这里我们先不管，反正它会被解析成为 IP 地址。那接下来是发送 HTTP 请求吗? 

​		不是的，**HTTP 是基于 TCP 协议的，当然是要先建立 TCP 连接了**，怎么建立呢?还记得第 11 节讲过的 三次握手吗? 

​		目前使用的 HTTP 协议大部分都是 1.1。在 1.1 的协议里面，默认是开启了 Keep-Alive 的，这样建立的 TCP 连接，就可以在多次请求中复用。 

​		学习了 TCP 之后，你应该知道，TCP 的三次握手和四次挥手，还是挺费劲的。如果好不容易建立了连接，然后就做了一点儿事情就结束了，有点儿浪费人力和物力。 

​		**HTTP 请求的构建 建立了连接以后，浏览器就要发送 HTTP 的请求。** 

​		请求的格式就像这样。 

​	![](/Users/nali/songyintao/SongYintao.github.io/img/http-1.png)

​		HTTP 的报文大概分为三大部分。第一部分是请求行，第二部分是请求的首部，第三部分才是请求的正 文实体。 

**第一部分:请求行** 

​		在请求行中，URL 就是 http://www.163.com ，版本为 HTTP 1.1。这里要说一下的，就是方法。方法 有几种类型。 

​		对于访问网页来讲，**最常用的类型就是GET**。顾名思义，GET 就是去服务器获取一些资源。对于访问网页来讲，要获取的资源往往是一个页面。其实也有很多其他的格式，比如说返回一个 JSON 字符串，到底要返回什么，是由服务器端的实现决定的。 

​		例如，在云计算中，如果我们的服务器端要提供一个基于 HTTP 协议的 API，获取所有云主机的列表， 这就会使用 GET 方法得到，返回的可能是一个 JSON 字符串。字符串里面是一个列表，列表里面是一项 的云主机的信息。 

​		**另外一种类型叫做POST**。它需要主动告诉服务端一些信息，而非获取。要告诉服务端什么呢?一般会放在正文里面。正文可以有各种各样的格式。常见的格式也是 JSON。 

​		例如，我们下一节要讲的支付场景，客户端就需要把“我是谁?我要支付多少?我要买啥?”告诉服务 器，这就需要通过 POST 方法。 

​		再如，在云计算里，如果我们的服务器端，要提供一个基于 HTTP 协议的创建云主机的 API，也会用到 POST 方法。这个时候往往需要将“我要创建多大的云主机?多少 CPU 多少内存?多大硬盘?”这些信 息放在 JSON 字符串里面，通过 POST 的方法告诉服务器端。 

​		**还有一种类型叫PUT**，就是**向指定资源位置上传最新内容**。但是，HTTP 的服务器往往是不允许上传文件的，所以 PUT 和 POST 就都变成了要传给服务器东西的方法。 

​		在实际使用过程中，这两者还会有稍许的区别。**POST 往往是用来创建一个资源的，而 PUT 往往是用来修改一个资源的**。 

​		例如，云主机已经创建好了，我想对这个云主机打一个标签，说明这个云主机是生产环境的，另外一个云主机是测试环境的。那怎么修改这个标签呢?往往就是用 PUT 方法。 

​		再有一种常见的就是**DELETE**。这个顾名思义就是**用来删除资源的**。例如，我们要删除一个云主机，就会 调用 DELETE 方法。 

**第二部分:首部字段** 

​		请求行下面就是我们的首部字段。首部是 key value，通过冒号分隔。这里面，往往保存了一些非常重要 的字段。 

​		例如，**Accept-Charset**，表示客户端可以接受的字符集。防止传过来的是另外的字符集，从而导致出现码。 

再如，Content-Type是指正文的格式。例如，我们进行 POST 的请求，如果正文是 JSON，那么我们就应该将这个值设置为 JSON。 

​		这里需要重点说一下的就是缓存。为啥要使用缓存呢?那是因为一个非常大的页面有很多东西。例如，我浏览一个商品的详情，里面有这个商品的价格、库存、展示图片、使用手册等等。商品的展示图片会保持较长时间不变，而库存会根据用户购买的情况经常改变。如果图片非常大，而库存数非常小，如果我们每次要更新数据的时候都要刷新整个页面，对于服务器的压力就会很大。
​		对于这种高并发场景下的系统，在真正的业务逻辑之前，都需要有个接入层，将这些静态资源的请求拦在最外面。

​		这个架构的图就像这样。 

